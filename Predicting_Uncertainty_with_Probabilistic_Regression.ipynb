{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f13cc6e",
   "metadata": {},
   "source": [
    "# Probabilistic Regression with NGBoost To Predict Uncertainty\n",
    "\n",
    "The goal of regression models is to make accurate point predictions with input from independent variables. However, in the real world, the actual value most likely ends up being higher or lower than this point prediction. Estimating the uncertainty in the predictions with a full probability distribution over the target space allows data scientists and stakeholders to analyze a range of likely values for the outcome, and probabilistic forecasting can quantify these uncertainties.\n",
    "\n",
    "Here, I use the NGBoost algorithm to predict a probability distribution of the outcome on the Ames housing dataset. NGBoost employs gradient boosting methods, which have been among the top performers in prediction accuracy for structured data. Three components are configured in NGBoost: (1) Base Learner (usually DecisionTree); (2) Probability Distribution (Normal, Log-Normal, Gamma etc); (3) Scoring rule (Maximum Likelihood Estimation (MLE), RMSE etc). For my model, I use DecisionTree as the base learner, Gamma distribution, and MLE as the scoring rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6c92b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade git+https://github.com/stanfordmlgroup/ngboost.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8acf42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "from ngboost import NGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import pandas as pd\n",
    "from ngboost.distns import Exponential, Normal, LogNormal, Gamma\n",
    "from scipy.stats import lognorm, norm, gamma\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import math\n",
    "from scipy import stats\n",
    "import shap\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "071a2905",
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_housing = pd.read_csv(\"datasets/AmesHousing.csv\")\n",
    "scoreid    = 533210020  # PID of select home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e73e7d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>Lot Config</th>\n",
       "      <th>Land Slope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition 1</th>\n",
       "      <th>Condition 2</th>\n",
       "      <th>Bldg Type</th>\n",
       "      <th>House Style</th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>Overall Cond</th>\n",
       "      <th>Year Built</th>\n",
       "      <th>Year Remod/Add</th>\n",
       "      <th>Roof Style</th>\n",
       "      <th>Roof Matl</th>\n",
       "      <th>Exterior 1st</th>\n",
       "      <th>Exterior 2nd</th>\n",
       "      <th>Mas Vnr Type</th>\n",
       "      <th>Mas Vnr Area</th>\n",
       "      <th>Exter Qual</th>\n",
       "      <th>Exter Cond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>Bsmt Qual</th>\n",
       "      <th>Bsmt Cond</th>\n",
       "      <th>Bsmt Exposure</th>\n",
       "      <th>BsmtFin Type 1</th>\n",
       "      <th>BsmtFin SF 1</th>\n",
       "      <th>BsmtFin Type 2</th>\n",
       "      <th>BsmtFin SF 2</th>\n",
       "      <th>Bsmt Unf SF</th>\n",
       "      <th>Total Bsmt SF</th>\n",
       "      <th>Heating</th>\n",
       "      <th>Heating QC</th>\n",
       "      <th>Central Air</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>1st Flr SF</th>\n",
       "      <th>2nd Flr SF</th>\n",
       "      <th>Low Qual Fin SF</th>\n",
       "      <th>Gr Liv Area</th>\n",
       "      <th>Bsmt Full Bath</th>\n",
       "      <th>Bsmt Half Bath</th>\n",
       "      <th>Full Bath</th>\n",
       "      <th>Half Bath</th>\n",
       "      <th>Bedroom AbvGr</th>\n",
       "      <th>Kitchen AbvGr</th>\n",
       "      <th>Kitchen Qual</th>\n",
       "      <th>TotRms AbvGrd</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>Fireplace Qu</th>\n",
       "      <th>Garage Type</th>\n",
       "      <th>Garage Yr Blt</th>\n",
       "      <th>Garage Finish</th>\n",
       "      <th>Garage Cars</th>\n",
       "      <th>Garage Area</th>\n",
       "      <th>Garage Qual</th>\n",
       "      <th>Garage Cond</th>\n",
       "      <th>Paved Drive</th>\n",
       "      <th>Wood Deck SF</th>\n",
       "      <th>Open Porch SF</th>\n",
       "      <th>Enclosed Porch</th>\n",
       "      <th>3Ssn Porch</th>\n",
       "      <th>Screen Porch</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Pool QC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc Feature</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>Sale Condition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>526301100</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>141.0</td>\n",
       "      <td>31770</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1960</td>\n",
       "      <td>1960</td>\n",
       "      <td>Hip</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>Plywood</td>\n",
       "      <td>Stone</td>\n",
       "      <td>112.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Gd</td>\n",
       "      <td>BLQ</td>\n",
       "      <td>639.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Fa</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1656</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1656</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>7</td>\n",
       "      <td>Typ</td>\n",
       "      <td>2</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>Fin</td>\n",
       "      <td>2.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>P</td>\n",
       "      <td>210</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>526350040</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>Rec</td>\n",
       "      <td>468.0</td>\n",
       "      <td>LwQ</td>\n",
       "      <td>144.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>882.0</td>\n",
       "      <td>GasA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>5</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>526351010</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1958</td>\n",
       "      <td>1958</td>\n",
       "      <td>Hip</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>108.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>923.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>GasA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>393</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>526353030</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>93.0</td>\n",
       "      <td>11160</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1968</td>\n",
       "      <td>1968</td>\n",
       "      <td>Hip</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>2110.0</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>2110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Ex</td>\n",
       "      <td>8</td>\n",
       "      <td>Typ</td>\n",
       "      <td>2</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>Fin</td>\n",
       "      <td>2.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>244000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>527105010</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>791.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>928.0</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>1629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Fin</td>\n",
       "      <td>2.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>212</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>189900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street  \\\n",
       "0      1  526301100           20        RL         141.0     31770   Pave   \n",
       "1      2  526350040           20        RH          80.0     11622   Pave   \n",
       "2      3  526351010           20        RL          81.0     14267   Pave   \n",
       "3      4  526353030           20        RL          93.0     11160   Pave   \n",
       "4      5  527105010           60        RL          74.0     13830   Pave   \n",
       "\n",
       "  Alley Lot Shape Land Contour Utilities Lot Config Land Slope Neighborhood  \\\n",
       "0   NaN       IR1          Lvl    AllPub     Corner        Gtl        NAmes   \n",
       "1   NaN       Reg          Lvl    AllPub     Inside        Gtl        NAmes   \n",
       "2   NaN       IR1          Lvl    AllPub     Corner        Gtl        NAmes   \n",
       "3   NaN       Reg          Lvl    AllPub     Corner        Gtl        NAmes   \n",
       "4   NaN       IR1          Lvl    AllPub     Inside        Gtl      Gilbert   \n",
       "\n",
       "  Condition 1 Condition 2 Bldg Type House Style  Overall Qual  Overall Cond  \\\n",
       "0        Norm        Norm      1Fam      1Story             6             5   \n",
       "1       Feedr        Norm      1Fam      1Story             5             6   \n",
       "2        Norm        Norm      1Fam      1Story             6             6   \n",
       "3        Norm        Norm      1Fam      1Story             7             5   \n",
       "4        Norm        Norm      1Fam      2Story             5             5   \n",
       "\n",
       "   Year Built  Year Remod/Add Roof Style Roof Matl Exterior 1st Exterior 2nd  \\\n",
       "0        1960            1960        Hip   CompShg      BrkFace      Plywood   \n",
       "1        1961            1961      Gable   CompShg      VinylSd      VinylSd   \n",
       "2        1958            1958        Hip   CompShg      Wd Sdng      Wd Sdng   \n",
       "3        1968            1968        Hip   CompShg      BrkFace      BrkFace   \n",
       "4        1997            1998      Gable   CompShg      VinylSd      VinylSd   \n",
       "\n",
       "  Mas Vnr Type  Mas Vnr Area Exter Qual Exter Cond Foundation Bsmt Qual  \\\n",
       "0        Stone         112.0         TA         TA     CBlock        TA   \n",
       "1          NaN           0.0         TA         TA     CBlock        TA   \n",
       "2      BrkFace         108.0         TA         TA     CBlock        TA   \n",
       "3          NaN           0.0         Gd         TA     CBlock        TA   \n",
       "4          NaN           0.0         TA         TA      PConc        Gd   \n",
       "\n",
       "  Bsmt Cond Bsmt Exposure BsmtFin Type 1  BsmtFin SF 1 BsmtFin Type 2  \\\n",
       "0        Gd            Gd            BLQ         639.0            Unf   \n",
       "1        TA            No            Rec         468.0            LwQ   \n",
       "2        TA            No            ALQ         923.0            Unf   \n",
       "3        TA            No            ALQ        1065.0            Unf   \n",
       "4        TA            No            GLQ         791.0            Unf   \n",
       "\n",
       "   BsmtFin SF 2  Bsmt Unf SF  Total Bsmt SF Heating Heating QC Central Air  \\\n",
       "0           0.0        441.0         1080.0    GasA         Fa           Y   \n",
       "1         144.0        270.0          882.0    GasA         TA           Y   \n",
       "2           0.0        406.0         1329.0    GasA         TA           Y   \n",
       "3           0.0       1045.0         2110.0    GasA         Ex           Y   \n",
       "4           0.0        137.0          928.0    GasA         Gd           Y   \n",
       "\n",
       "  Electrical  1st Flr SF  2nd Flr SF  Low Qual Fin SF  Gr Liv Area  \\\n",
       "0      SBrkr        1656           0                0         1656   \n",
       "1      SBrkr         896           0                0          896   \n",
       "2      SBrkr        1329           0                0         1329   \n",
       "3      SBrkr        2110           0                0         2110   \n",
       "4      SBrkr         928         701                0         1629   \n",
       "\n",
       "   Bsmt Full Bath  Bsmt Half Bath  Full Bath  Half Bath  Bedroom AbvGr  \\\n",
       "0             1.0             0.0          1          0              3   \n",
       "1             0.0             0.0          1          0              2   \n",
       "2             0.0             0.0          1          1              3   \n",
       "3             1.0             0.0          2          1              3   \n",
       "4             0.0             0.0          2          1              3   \n",
       "\n",
       "   Kitchen AbvGr Kitchen Qual  TotRms AbvGrd Functional  Fireplaces  \\\n",
       "0              1           TA              7        Typ           2   \n",
       "1              1           TA              5        Typ           0   \n",
       "2              1           Gd              6        Typ           0   \n",
       "3              1           Ex              8        Typ           2   \n",
       "4              1           TA              6        Typ           1   \n",
       "\n",
       "  Fireplace Qu Garage Type  Garage Yr Blt Garage Finish  Garage Cars  \\\n",
       "0           Gd      Attchd         1960.0           Fin          2.0   \n",
       "1          NaN      Attchd         1961.0           Unf          1.0   \n",
       "2          NaN      Attchd         1958.0           Unf          1.0   \n",
       "3           TA      Attchd         1968.0           Fin          2.0   \n",
       "4           TA      Attchd         1997.0           Fin          2.0   \n",
       "\n",
       "   Garage Area Garage Qual Garage Cond Paved Drive  Wood Deck SF  \\\n",
       "0        528.0          TA          TA           P           210   \n",
       "1        730.0          TA          TA           Y           140   \n",
       "2        312.0          TA          TA           Y           393   \n",
       "3        522.0          TA          TA           Y             0   \n",
       "4        482.0          TA          TA           Y           212   \n",
       "\n",
       "   Open Porch SF  Enclosed Porch  3Ssn Porch  Screen Porch  Pool Area Pool QC  \\\n",
       "0             62               0           0             0          0     NaN   \n",
       "1              0               0           0           120          0     NaN   \n",
       "2             36               0           0             0          0     NaN   \n",
       "3              0               0           0             0          0     NaN   \n",
       "4             34               0           0             0          0     NaN   \n",
       "\n",
       "   Fence Misc Feature  Misc Val  Mo Sold  Yr Sold Sale Type Sale Condition  \\\n",
       "0    NaN          NaN         0        5     2010       WD          Normal   \n",
       "1  MnPrv          NaN         0        6     2010       WD          Normal   \n",
       "2    NaN         Gar2     12500        6     2010       WD          Normal   \n",
       "3    NaN          NaN         0        4     2010       WD          Normal   \n",
       "4  MnPrv          NaN         0        3     2010       WD          Normal   \n",
       "\n",
       "   SalePrice  \n",
       "0     215000  \n",
       "1     105000  \n",
       "2     172000  \n",
       "3     244000  \n",
       "4     189900  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "ames_housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7b0bb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed values\n",
    "seeds = [324343, 454325, 465365, 787867, 645767,\n",
    "         235436, 135436, 976876, 452454, 867356]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff27589c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_y_split(df):\n",
    "    X = df.drop(['SalePrice', 'Order', 'PID'], axis=1)\n",
    "    y = df['SalePrice']\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1de517d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into X and y\n",
    "# Hold out home-of-interest only\n",
    "\n",
    "def dataset_split(data, start = 0, end = 360000000):\n",
    "    # set up constraint\n",
    "    scoring = data[data.PID==scoreid].reset_index(drop = True)\n",
    "    data = data[(data.SalePrice>= start)&(data.SalePrice<=end)].reset_index(drop = True)\n",
    "    X_id = list(data['PID'].unique())\n",
    "    \n",
    "    dataset = data[data.PID.isin(X_id)].reset_index(drop=True)\n",
    "    dataset = dataset[dataset.PID!=scoreid].reset_index(drop=True)\n",
    "    \n",
    "    x, y = x_y_split(dataset)\n",
    "    x_score, y_score = x_y_split(scoring)\n",
    "    \n",
    "    return x, y, dataset, scoring, x_score, y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6113979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterSampler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f95be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple wrapper to set up the regressor\n",
    "\n",
    "def initialize_reg(n_estimators     = 500, \n",
    "                   learning_rate    = 0.1,\n",
    "                   minibatch_frac   = 1.0,\n",
    "                   col_sample       = 1.0,\n",
    "                   min_samples_leaf = 1,\n",
    "                   max_depth        = 3,\n",
    "                   dist             = Normal,\n",
    "                   verbose = False,\n",
    "                   random_state = None):\n",
    "    reg = NGBRegressor( Base           = DecisionTreeRegressor(\n",
    "                                            min_samples_leaf = min_samples_leaf,\n",
    "                                            max_depth        = max_depth,\n",
    "                                            random_state     = random_state ),\n",
    "                       Dist = dist,\n",
    "                        n_estimators   = n_estimators,\n",
    "                        learning_rate  = learning_rate,\n",
    "                        minibatch_frac = minibatch_frac,\n",
    "                        col_sample     = col_sample,\n",
    "                        random_state   = random_state,\n",
    "                        verbose = verbose)\n",
    "    return clone(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "624d1fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User inputs\n",
    "\n",
    "data_dist = Gamma\n",
    "\n",
    "param_dist = {\n",
    "              'learning_rate': stats.uniform(0.009, 0.08),\n",
    "              'minibatch_frac': stats.uniform(0.3, 0.7),\n",
    "              'col_sample': stats.uniform(0.5, 0.45),\n",
    "              'max_depth': [3, 4, 5, 6, 7, 8, 9],\n",
    "              'min_samples_leaf': [1, 2, 3]\n",
    "             }\n",
    "n_param_samples = 6       # Number of random hyperparameter combinations to test\n",
    "n_folds = 3                # Number of CV folds for each hyperparameter combination\n",
    "max_n_estimators = 10000   # Make this a large number, early stopping will kick in\n",
    "early_stopping_rounds = 10\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ea32ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SalePrice $ range\n",
    "\n",
    "start_main = 0\n",
    "end_main = 99999999999999  \n",
    "start_alt = 80000\n",
    "end_alt = 99999999999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5a46c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the best parameter set for a given metric and put it into a dict.\n",
    "\n",
    "def get_search_result(param_set_results, param_list, metric = 'rmse'):\n",
    "    \n",
    "    best_param_set_index = \\\n",
    "        np.argmin([x['best_{}_score'.format(metric)] for x in param_set_results])\n",
    "    best_param_set = param_list[best_param_set_index]\n",
    "    best_param_set['n_estimators'] = \\\n",
    "        param_set_results[best_param_set_index]['best_{}_iteration'.format(metric)]\n",
    "    best_score = param_set_results[best_param_set_index]['best_{}_score'.format(metric)]\n",
    "\n",
    "    search_result = {}\n",
    "\n",
    "    search_result['best_score'] = best_score\n",
    "    search_result['best_param_set'] = best_param_set\n",
    "\n",
    "    return(search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88b13ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(df_imp, feat):\n",
    "    # Fill missing values with \"Missing\"\n",
    "    df_imp[feat] = df_imp[feat].fillna(\"Missing\")\n",
    "    \n",
    "    # Initialize OneHotEncoder\n",
    "    enc = OneHotEncoder()\n",
    "    \n",
    "    # Create a OneHotEncoder\n",
    "    enc = OneHotEncoder(sparse_output=False)  # Set sparse=False to get a dense array\n",
    "\n",
    "    # Fit and transform the encoder on the specified columns\n",
    "    enc_data = enc.fit_transform(df_imp[feat])\n",
    "\n",
    "    # Get the feature names from the encoder\n",
    "    feature_names = enc.get_feature_names_out(input_features=feat)\n",
    "\n",
    "    # Create a new DataFrame with proper column names\n",
    "    enc_df = pd.DataFrame(enc_data, columns=feature_names)\n",
    "        \n",
    "    # Drop the original categorical columns from the original DataFrame\n",
    "    df_imp = df_imp.drop(columns=feat)\n",
    "    \n",
    "    # Concatenate the original DataFrame with the encoded DataFrame\n",
    "    final_df = pd.concat([df_imp, enc_df], axis=1)\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09c0641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_enc(df, feat):\n",
    "    \n",
    "    # Perform frequency encoding for each categorical column\n",
    "    for col in feat:\n",
    "        # Fill missing values with \"Missing\"\n",
    "        df[col].fillna(\"Missing\", inplace=True)\n",
    "        \n",
    "        # Calculate frequencies of each category\n",
    "        freq = df[col].value_counts().to_dict()\n",
    "    \n",
    "        # Replace the original values with frequencies\n",
    "        df[col] = df[col].map(freq)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0ea3a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the fold data\n",
    "folds = KFold(n_splits = n_folds, shuffle = True, random_state = random_state)\n",
    "imp = SimpleImputer()\n",
    "\n",
    "def folding(X, y):\n",
    "    fold_data = list()\n",
    "    for _, [train_index, test_index] in enumerate(folds.split(X)):\n",
    "        X_train_fold, X_test_fold = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "        y_train_fold, y_test_fold = y.iloc[train_index].values.ravel(), \\\n",
    "                            y.iloc[test_index].values.ravel()\n",
    "        \n",
    "        # Impute missing values since ngboost doesn't handle missingness\n",
    "        imp.fit(X_train_fold)\n",
    "        X_train_fold = imp.transform(X_train_fold)\n",
    "        X_test_fold  = imp.transform(X_test_fold)\n",
    "        \n",
    "        fold_data.append({'X_train'     : X_train_fold,\n",
    "                          'y_train'     : y_train_fold,\n",
    "                          'train_index' : train_index,\n",
    "                          'X_test'      : X_test_fold,\n",
    "                          'y_test'      : y_test_fold,\n",
    "                          'test_index'  : test_index})\n",
    "        \n",
    "    return fold_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95d0347a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "906e8e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipelineJY(Pipeline):\n",
    "\n",
    "    def pred_dist(self, X, **predict_params):\n",
    "        \"\"\"Transform the data, and apply `pred_dist` with the final estimator\n",
    "        (NGBRegressor).\n",
    "        Call `transform` of each transformer in the pipeline. The transformed\n",
    "        data are finally passed to the final estimator that calls `pred_dist`\n",
    "        method. Only valid if the final estimator implements `pred_dist`.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : iterable\n",
    "            Data to predict on. Must fulfill input requirements of first step\n",
    "            of the pipeline.\n",
    "        **predict_params : dict of string -> object\n",
    "            Parameters to the ``pred_dist`` called at the end of all\n",
    "            transformations in the pipeline. Note that while this may be\n",
    "            used to return uncertainties from some models with return_std\n",
    "            or return_cov, uncertainties that are generated by the\n",
    "            transformations in the pipeline are not propagated to the\n",
    "            final estimator.\n",
    "        Returns\n",
    "        -------\n",
    "        y_pred : ndarray\n",
    "            Result of calling `pred_dist` on the final estimator\n",
    "        \"\"\"\n",
    "        Xt = X.copy()\n",
    "        for _, name, transform in self._iter(with_final=False):\n",
    "            Xt = transform.transform(Xt)      \n",
    "        dists = self.steps[-1][1].pred_dist(Xt, **predict_params)\n",
    "        ret_val = dists.params['alpha']\n",
    "        ret_val = np.vstack([dists.params['alpha'],\n",
    "                             dists.params['beta']]).T\n",
    "        return ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e63d1dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df of predicted, min-max probability intervals, and observed values\n",
    "def pred_dist_info(y, y_pred_params, data, pi_range = [0.05, 0.95]):\n",
    "    \n",
    "    alpha     = y_pred_params[:,0]\n",
    "    beta = y_pred_params[:,1]\n",
    "    \n",
    "    y_pred_mean = alpha / beta\n",
    "    y_pred_median = gamma.ppf(0.5, a = alpha, scale=1/beta)\n",
    "    y_pred = y_pred_median\n",
    "    \n",
    "    errors = [y_pred -  gamma.ppf(pi_range[0], a = alpha, scale=1/beta),\n",
    "              -y_pred + gamma.ppf(pi_range[1], a = alpha, scale=1/beta)]\n",
    "\n",
    "    test = pd.DataFrame({\"observe\"     : y.values.flatten(),\n",
    "                         \"prediction\"  : y_pred,\n",
    "                         \"error_minus\" : errors[0],\n",
    "                         \"error_plus\"  : errors[1],\n",
    "                         \"observed\"    : y.values.flatten(),\n",
    "                         \"predicted\"   : y_pred,\n",
    "                         \"lower_range\" : y_pred - errors[0],\n",
    "                         \"upper_range\" : y_pred + errors[1]}).reset_index(drop=True)\n",
    "    \n",
    "    for column in ['observed', 'predicted', 'lower_range', 'upper_range']:\n",
    "        test[column] = test[column].apply(lambda x : '${0:,.0f}'.format(x))\n",
    "    \n",
    "    test = data['PID'].to_frame().merge(test, how='inner', left_index=True, right_index=True)\n",
    "    test['held_out'] = np.where(test['PID']==scoreid, 'yes', 'no')\n",
    "    \n",
    "    return test, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "826f09e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_outliers(df, replace):\n",
    "    # Calculate Q1 and Q2 quantile\n",
    "    q = df.agg('quantile', q=[.25, .75])\n",
    "\n",
    "    # Calculate IQR = Q2 - Q1\n",
    "    iqr = q.loc[.75] - q.loc[.25]\n",
    "\n",
    "    # Calculate lower and upper limits to decide outliers\n",
    "    lower = q.loc[.25] - 1.5 * iqr\n",
    "    upper = q.loc[.75] + 1.5 * iqr\n",
    "\n",
    "    # Replace the values that does not lies between [lower, upper]\n",
    "    return df.where(df.ge(lower) & df.le(upper), replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa76b2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_null(df):\n",
    "    null_count = df.isnull().sum()\n",
    "    null_pct = ((df.isnull().sum())/(df.isnull().count()))*100\n",
    "    null_type = df.dtypes\n",
    "    missing_data = pd.concat([null_count, null_pct, null_type], axis = 1,\n",
    "                             keys = ['Null Values', 'Percent of Total', 'Data Type'])\n",
    "    missing_data = missing_data.sort_values(by = 'Percent of Total', ascending = False).round(2)\n",
    "    \n",
    "    return missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fedb9765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Null Values</th>\n",
       "      <th>Percent of Total</th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pool QC</th>\n",
       "      <td>2917</td>\n",
       "      <td>99.56</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Misc Feature</th>\n",
       "      <td>2824</td>\n",
       "      <td>96.38</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alley</th>\n",
       "      <td>2732</td>\n",
       "      <td>93.24</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fence</th>\n",
       "      <td>2358</td>\n",
       "      <td>80.48</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mas Vnr Type</th>\n",
       "      <td>1775</td>\n",
       "      <td>60.58</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fireplace Qu</th>\n",
       "      <td>1422</td>\n",
       "      <td>48.53</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lot Frontage</th>\n",
       "      <td>490</td>\n",
       "      <td>16.72</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Garage Cond</th>\n",
       "      <td>159</td>\n",
       "      <td>5.43</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Garage Finish</th>\n",
       "      <td>159</td>\n",
       "      <td>5.43</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Garage Yr Blt</th>\n",
       "      <td>159</td>\n",
       "      <td>5.43</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Garage Qual</th>\n",
       "      <td>159</td>\n",
       "      <td>5.43</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Garage Type</th>\n",
       "      <td>157</td>\n",
       "      <td>5.36</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bsmt Exposure</th>\n",
       "      <td>83</td>\n",
       "      <td>2.83</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFin Type 2</th>\n",
       "      <td>81</td>\n",
       "      <td>2.76</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bsmt Qual</th>\n",
       "      <td>80</td>\n",
       "      <td>2.73</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bsmt Cond</th>\n",
       "      <td>80</td>\n",
       "      <td>2.73</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFin Type 1</th>\n",
       "      <td>80</td>\n",
       "      <td>2.73</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mas Vnr Area</th>\n",
       "      <td>23</td>\n",
       "      <td>0.78</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bsmt Full Bath</th>\n",
       "      <td>2</td>\n",
       "      <td>0.07</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bsmt Half Bath</th>\n",
       "      <td>2</td>\n",
       "      <td>0.07</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Null Values  Percent of Total Data Type\n",
       "Pool QC                2917             99.56    object\n",
       "Misc Feature           2824             96.38    object\n",
       "Alley                  2732             93.24    object\n",
       "Fence                  2358             80.48    object\n",
       "Mas Vnr Type           1775             60.58    object\n",
       "Fireplace Qu           1422             48.53    object\n",
       "Lot Frontage            490             16.72   float64\n",
       "Garage Cond             159              5.43    object\n",
       "Garage Finish           159              5.43    object\n",
       "Garage Yr Blt           159              5.43   float64\n",
       "Garage Qual             159              5.43    object\n",
       "Garage Type             157              5.36    object\n",
       "Bsmt Exposure            83              2.83    object\n",
       "BsmtFin Type 2           81              2.76    object\n",
       "Bsmt Qual                80              2.73    object\n",
       "Bsmt Cond                80              2.73    object\n",
       "BsmtFin Type 1           80              2.73    object\n",
       "Mas Vnr Area             23              0.78   float64\n",
       "Bsmt Full Bath            2              0.07   float64\n",
       "Bsmt Half Bath            2              0.07   float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values\n",
    "check_null(ames_housing).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee640db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with >= 50% null values\n",
    "ames_housing.drop(columns=['Pool QC', 'Misc Feature', 'Alley', 'Fence', 'Mas Vnr Type', 'Fireplace Qu'],\n",
    "                  inplace=True)\n",
    "\n",
    "# Replace outliers in numerical columns with NA\n",
    "housing_num = mask_outliers(ames_housing.select_dtypes(\"number\"), np.nan)\n",
    "\n",
    "# Get list of numerical feature names\n",
    "# Remove 'Order', 'PID', 'SalePrice'\n",
    "num_feat = list(ames_housing.select_dtypes(\"number\").columns.difference(['Order', 'PID', 'SalePrice']))\n",
    "\n",
    "# Original number features\n",
    "orig_num_feat = list(ames_housing.select_dtypes(\"number\").columns)\n",
    "\n",
    "# Get list of categorical feature names\n",
    "cat_feat = list(ames_housing.columns.difference(orig_num_feat))\n",
    "cat_feat_freq = ['Exterior 1st', 'Exterior 2nd', 'Neighborhood']\n",
    "one_hot_feat = list(ames_housing.columns.difference(orig_num_feat).difference(cat_feat_freq))\n",
    "\n",
    "# Join numerical and categorical columns\n",
    "housing_cat = ames_housing[ames_housing.columns.difference(orig_num_feat)]\n",
    "housing_new = housing_num.merge(housing_cat, how='inner', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20160d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncode categorical variables that each have <= 10 categories in df\n",
    "# Treat NA's as a category\n",
    "housing_new = one_hot(housing_new, one_hot_feat)\n",
    "\n",
    "# FrequencyEncode categorical variables that each have > 10 categories in df\n",
    "# Treat NA's as a category\n",
    "housing_new = freq_enc(housing_new, cat_feat_freq)\n",
    "\n",
    "# Split dataset\n",
    "X, y, dataset, scoring, X_score, y_score = dataset_split(housing_new, start = start_main, end = end_main)\n",
    "\n",
    "fold_data = folding(X, y)\n",
    "\n",
    "best_nll_score = list()\n",
    "nll_col_sample = list()\n",
    "nll_learning_rate = list()\n",
    "nll_max_depth = list()\n",
    "nll_min_samples_leaf = list()\n",
    "nll_minibatch_frac = list()\n",
    "nll_n_estimators = list()\n",
    "wmape = list()\n",
    "house_sel_90_df = pd.DataFrame()\n",
    "house_sel_80_df = pd.DataFrame()\n",
    "house_sel_70_df = pd.DataFrame()\n",
    "intervals_percent_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96d4f43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Null Values</th>\n",
       "      <th>Percent of Total</th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lot Frontage</th>\n",
       "      <td>677</td>\n",
       "      <td>23.11</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Enclosed Porch</th>\n",
       "      <td>459</td>\n",
       "      <td>15.67</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFin SF 2</th>\n",
       "      <td>352</td>\n",
       "      <td>12.01</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Screen Porch</th>\n",
       "      <td>256</td>\n",
       "      <td>8.74</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall Cond</th>\n",
       "      <td>252</td>\n",
       "      <td>8.60</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mas Vnr Area</th>\n",
       "      <td>223</td>\n",
       "      <td>7.61</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MS SubClass</th>\n",
       "      <td>208</td>\n",
       "      <td>7.10</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bsmt Half Bath</th>\n",
       "      <td>177</td>\n",
       "      <td>6.04</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Garage Yr Blt</th>\n",
       "      <td>162</td>\n",
       "      <td>5.53</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open Porch SF</th>\n",
       "      <td>159</td>\n",
       "      <td>5.43</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SalePrice</th>\n",
       "      <td>137</td>\n",
       "      <td>4.68</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kitchen AbvGr</th>\n",
       "      <td>134</td>\n",
       "      <td>4.57</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lot Area</th>\n",
       "      <td>127</td>\n",
       "      <td>4.33</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Bsmt SF</th>\n",
       "      <td>124</td>\n",
       "      <td>4.23</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Misc Val</th>\n",
       "      <td>103</td>\n",
       "      <td>3.52</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bedroom AbvGr</th>\n",
       "      <td>78</td>\n",
       "      <td>2.66</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gr Liv Area</th>\n",
       "      <td>75</td>\n",
       "      <td>2.56</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wood Deck SF</th>\n",
       "      <td>67</td>\n",
       "      <td>2.29</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bsmt Unf SF</th>\n",
       "      <td>57</td>\n",
       "      <td>1.95</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotRms AbvGrd</th>\n",
       "      <td>51</td>\n",
       "      <td>1.74</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Null Values  Percent of Total Data Type\n",
       "Lot Frontage            677             23.11   float64\n",
       "Enclosed Porch          459             15.67   float64\n",
       "BsmtFin SF 2            352             12.01   float64\n",
       "Screen Porch            256              8.74   float64\n",
       "Overall Cond            252              8.60   float64\n",
       "Mas Vnr Area            223              7.61   float64\n",
       "MS SubClass             208              7.10   float64\n",
       "Bsmt Half Bath          177              6.04   float64\n",
       "Garage Yr Blt           162              5.53   float64\n",
       "Open Porch SF           159              5.43   float64\n",
       "SalePrice               137              4.68   float64\n",
       "Kitchen AbvGr           134              4.57   float64\n",
       "Lot Area                127              4.33   float64\n",
       "Total Bsmt SF           124              4.23   float64\n",
       "Misc Val                103              3.52   float64\n",
       "Bedroom AbvGr            78              2.66   float64\n",
       "Gr Liv Area              75              2.56   float64\n",
       "Wood Deck SF             67              2.29   float64\n",
       "Bsmt Unf SF              57              1.95   float64\n",
       "TotRms AbvGrd            51              1.74   float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_null(housing_new).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "234028a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Lot Frontage column\n",
    "housing_new.drop(columns=['Lot Frontage'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d820eeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the random search\n",
    "\n",
    "# Two different metrics to minimize:\n",
    "# RMSE and negative log likelihood\n",
    "# With early stopping\n",
    "\n",
    "def test_early_stop(metric_vs_stage, early_stopping_rounds):\n",
    "    if len(metric_vs_stage) - np.argmin(metric_vs_stage) \\\n",
    "            > early_stopping_rounds:\n",
    "        best_iteration = np.argmin(metric_vs_stage)\n",
    "        best_test_score = metric_vs_stage[best_iteration]\n",
    "        return((best_iteration, best_test_score))\n",
    "    else:\n",
    "        return((-1,-1))\n",
    "\n",
    "def random_search(x, data_fold, best_nll_score, wmape_sel, col_sample, learning_rate, max_depth,\n",
    "                  min_samples_leaf, minibatch_frac, n_estimators, sel_90_df, sel_80_df,\n",
    "                  sel_70_df, intervals_percent_df, seeds, modelrun):\n",
    "    param_list = list(ParameterSampler(param_dist,\n",
    "                                       n_iter = n_param_samples,\n",
    "                                       random_state = random_state))\n",
    "    \n",
    "    y_pred_train_folds = np.zeros(len(x))\n",
    "    y_pred_test_folds  = np.zeros(len(x))\n",
    "    y_pred_nll_train_folds = np.zeros(len(x))\n",
    "    y_pred_nll_test_folds  = np.zeros(len(x))\n",
    "    param_set_scores = np.zeros(len(param_list))\n",
    "    param_set_results = list()\n",
    "    for param_index, param_set in enumerate(param_list):\n",
    "        print(param_set)\n",
    "        \n",
    "        # Initialize models for this hyperparameter set\n",
    "        for fold in data_fold:\n",
    "            fold['model'] = initialize_reg(**param_set, n_estimators = 1,\n",
    "                                           dist=data_dist,\n",
    "                                           random_state=seeds[modelrun])\n",
    "            \n",
    "        test_rmse_vs_stage = list()\n",
    "        train_rmse_vs_stage = list()\n",
    "        test_nll_vs_stage = list()\n",
    "        train_nll_vs_stage = list()\n",
    "        for i in range(max_n_estimators):\n",
    "            \n",
    "            for fold in data_fold:\n",
    "                fold['model'].fit(fold['X_train'], fold['y_train'])\n",
    "                \n",
    "                # Get train- and test-fold predictions for this boosting stage\n",
    "                y_pred_train_folds[fold['train_index']] = fold['model'].predict(fold['X_train'])\n",
    "                y_pred_test_folds[fold['test_index']]   = fold['model'].predict(fold['X_test'])\n",
    "                y_pred_nll_train_folds[fold['train_index']] = \\\n",
    "                    -fold['model'].pred_dist(fold['X_train']).logpdf(fold['y_train'])\n",
    "                y_pred_nll_test_folds[fold['test_index']]   = \\\n",
    "                    -fold['model'].pred_dist(fold['X_test']).logpdf(fold['y_test'])\n",
    "            \n",
    "            # Compute metric at this number of trees\n",
    "            stage_test_rmse  = mean_squared_error(y_pred_test_folds, y, squared=False)\n",
    "            stage_train_rmse = mean_squared_error(y_pred_train_folds, y, squared=False)\n",
    "            stage_test_nll  = y_pred_nll_test_folds.mean()\n",
    "            stage_train_nll = y_pred_nll_train_folds.mean()\n",
    "        \n",
    "            test_rmse_vs_stage.append(stage_test_rmse)\n",
    "            train_rmse_vs_stage.append(stage_train_rmse)\n",
    "            test_nll_vs_stage.append(stage_test_nll)\n",
    "            train_nll_vs_stage.append(stage_train_nll)\n",
    "        \n",
    "            if i % 10 == 0:\n",
    "                print(('Iteration {}: RMSE - train folds {:,.2f}, test folds {:,.2f}' +\n",
    "                       '\\n\\t\\tNLL - train folds {:,.3f}, test folds {:,.3f}').\\\n",
    "                      format(i, stage_train_rmse, stage_test_rmse, \n",
    "                             stage_train_nll, stage_test_nll))\n",
    "        \n",
    "            # Stop if early stopping criterion is met\n",
    "            best_rmse_iteration, best_test_rmse = test_early_stop(test_rmse_vs_stage,\n",
    "                                                                  early_stopping_rounds)\n",
    "            best_nll_iteration, best_test_nll   = test_early_stop(test_nll_vs_stage,\n",
    "                                                                  early_stopping_rounds)\n",
    "\n",
    "            if (best_rmse_iteration > 0) & (best_nll_iteration > 0):\n",
    "                print('Best iterations: rmse - {:,.2f}, {:,.2f}\\n\\t\\t nll - {:,.3f}, {:,.3f}'.format(\n",
    "                    best_rmse_iteration, best_test_rmse, best_nll_iteration, best_test_nll))\n",
    "                break\n",
    "            \n",
    "        param_set_results.append({'best_rmse_iteration': best_rmse_iteration,\n",
    "                                  'best_rmse_score'    : best_test_rmse,\n",
    "                                  'best_nll_iteration' : best_nll_iteration,\n",
    "                                  'best_nll_score'     : best_test_nll})\n",
    "    \n",
    "    search_result = get_search_result(param_set_results, param_list, metric = 'nll')\n",
    "    best_nll_score.append(search_result.get('best_score'))\n",
    "    \n",
    "    nll_best_param = list(search_result['best_param_set'].values())\n",
    "    col_sample.append(nll_best_param[0])\n",
    "    learning_rate.append(nll_best_param[1])\n",
    "    max_depth.append(nll_best_param[2])\n",
    "    min_samples_leaf.append(nll_best_param[3])\n",
    "    minibatch_frac.append(nll_best_param[4])\n",
    "    n_estimators.append(nll_best_param[5])\n",
    "    \n",
    "    # Set up steps and pipeline\n",
    "    steps = [('imputer', SimpleImputer()),\n",
    "             ('reg', initialize_reg(**search_result['best_param_set'],\n",
    "                                    dist=data_dist,\n",
    "                                    random_state=42))]\n",
    "    pipeline = PipelineJY(steps)\n",
    "    \n",
    "    # Get 'alpha', 'beta', and predicted opening value\n",
    "    y_pred_params_cv = cross_val_predict(pipeline, x, y, cv=folds, method=\"pred_dist\")\n",
    "    y_pred = cross_val_predict(pipeline, x, y, cv=folds, method=\"predict\")\n",
    "    \n",
    "    # Create MAPE df and store MAPE\n",
    "    mape_df = pd.DataFrame({'PID'            : dataset['PID'],\n",
    "                            'SalePrice'      : y,\n",
    "                            'predicted'      : y_pred,\n",
    "                            'SellingPrice'   : y,\n",
    "                            'predict'        : y_pred})\n",
    "    \n",
    "    for column in ['SellingPrice', 'predict']:\n",
    "        mape_df[column] = mape_df[column].apply(lambda x : '${0:,.0f}'.format(x))\n",
    "        \n",
    "    wmape_run = round((np.abs(mape_df['SalePrice'].values - mape_df['predicted'].values).sum()\n",
    "                      / np.abs(mape_df['SalePrice'].values).sum()), 7)\n",
    "    wmape_sel.append(wmape_run)\n",
    "    \n",
    "    # Collect prediction and errors for home for each run and put in df\n",
    "    # Middle 90%\n",
    "    pred_dist_df, y_errors = pred_dist_info(y, y_pred_params_cv, dataset, pi_range = [0.05, 0.95])\n",
    "\n",
    "    obs_percent_90 = np.mean(((y_pred + y_errors[1]) > pred_dist_df['observe']) &\n",
    "                             ((y_pred - y_errors[0]) < pred_dist_df['observe'])) * 100\n",
    "\n",
    "    sel_90_run = pred_dist_df[pred_dist_df['held_out']=='yes'\n",
    "                                   ].drop('held_out', axis=1).reset_index(drop=True)\n",
    "    sel_90_run['seed'] = modelrun + 1\n",
    "    sel_90_run['type'] = 'middle_90'\n",
    "    sel_90_df = pd.concat([sel_90_df, sel_90_run])\n",
    "\n",
    "    # Middle 80%\n",
    "    pred_dist_df, y_errors = pred_dist_info(y, y_pred_params_cv, dataset, pi_range = [0.1, 0.9])\n",
    "\n",
    "    obs_percent_80 = np.mean(((y_pred + y_errors[1]) > pred_dist_df['observe']) &\n",
    "                             ((y_pred - y_errors[0]) < pred_dist_df['observe'])) * 100\n",
    "\n",
    "    sel_80_run = pred_dist_df[pred_dist_df['held_out']=='yes'\n",
    "                            ].drop('held_out', axis=1).reset_index(drop=True)\n",
    "    sel_80_run['seed'] = modelrun + 1\n",
    "    sel_80_run['type'] = 'middle_80'\n",
    "    sel_80_df = pd.concat([sel_80_df, sel_80_run])\n",
    "    \n",
    "    # Middle 70%\n",
    "    pred_dist_df, y_errors = pred_dist_info(y, y_pred_params_cv, dataset, pi_range = [0.15, 0.85])\n",
    "\n",
    "    obs_percent_70 = np.mean(((y_pred + y_errors[1]) > pred_dist_df['observe']) &\n",
    "                             ((y_pred - y_errors[0]) < pred_dist_df['observe'])) * 100\n",
    "\n",
    "    sel_70_run = pred_dist_df[pred_dist_df['held_out']=='yes'\n",
    "                            ].drop('held_out', axis=1).reset_index(drop=True)\n",
    "    sel_70_run['seed'] = modelrun + 1\n",
    "    sel_70_run['type'] = 'middle_70'\n",
    "    sel_70_df = pd.concat([sel_70_df, sel_70_run])\n",
    "    \n",
    "    # Create df of mean percent of intervals with observed value\n",
    "    intervals_percent_run = pd.DataFrame.from_dict({'Middle_90%' : obs_percent_90,\n",
    "                                                    'Middle_80%' : obs_percent_80,\n",
    "                                                    'Middle_70%' : obs_percent_70\n",
    "                                                   }, orient='index').T\n",
    "    intervals_percent_df = pd.concat([intervals_percent_df, intervals_percent_run])\n",
    "    \n",
    "    return best_nll_score, wmape_sel, col_sample, learning_rate, max_depth, min_samples_leaf, minibatch_frac, n_estimators, \\\n",
    "            sel_90_df, sel_80_df, sel_70_df, intervals_percent_df, mape_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7127ad7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'col_sample': 0.6685430534813132, 'learning_rate': 0.0850571445127933, 'max_depth': 5, 'min_samples_leaf': 1, 'minibatch_frac': 0.7177951105625409}\n",
      "Iteration 0: RMSE - train folds 56,893.86, test folds 56,870.34\n",
      "\t\tNLL - train folds 12.305, test folds 12.312\n",
      "Iteration 10: RMSE - train folds 56,443.77, test folds 56,641.77\n",
      "\t\tNLL - train folds 12.291, test folds 12.304\n",
      "Iteration 20: RMSE - train folds 57,100.01, test folds 57,123.76\n",
      "\t\tNLL - train folds 12.307, test folds 12.314\n",
      "Best iterations: rmse - 10.00, 56,641.77\n",
      "\t\t nll - 6.000, 12.302\n",
      "{'col_sample': 0.700624738784116, 'learning_rate': 0.016997993265440228, 'max_depth': 5, 'min_samples_leaf': 1, 'minibatch_frac': 0.7207805082202461}\n",
      "Iteration 0: RMSE - train folds 58,496.51, test folds 58,561.22\n",
      "\t\tNLL - train folds 12.348, test folds 12.351\n",
      "Iteration 10: RMSE - train folds 58,437.08, test folds 58,469.93\n",
      "\t\tNLL - train folds 12.344, test folds 12.348\n",
      "Iteration 20: RMSE - train folds 58,600.41, test folds 58,630.12\n",
      "\t\tNLL - train folds 12.349, test folds 12.352\n",
      "Best iterations: rmse - 10.00, 58,469.93\n",
      "\t\t nll - 10.000, 12.348\n",
      "{'col_sample': 0.8186326600082205, 'learning_rate': 0.010646759543664196, 'max_depth': 4, 'min_samples_leaf': 2, 'minibatch_frac': 0.44863737747479326}\n",
      "Iteration 0: RMSE - train folds 58,743.15, test folds 58,800.84\n",
      "\t\tNLL - train folds 12.353, test folds 12.356\n",
      "Iteration 10: RMSE - train folds 58,709.25, test folds 58,763.87\n",
      "\t\tNLL - train folds 12.353, test folds 12.355\n",
      "Best iterations: rmse - 1.00, 58,715.67\n",
      "\t\t nll - 9.000, 12.355\n",
      "{'col_sample': 0.5818212352431953, 'learning_rate': 0.023672360788274706, 'max_depth': 6, 'min_samples_leaf': 2, 'minibatch_frac': 0.6673295021425665}\n",
      "Iteration 0: RMSE - train folds 58,447.02, test folds 58,522.36\n",
      "\t\tNLL - train folds 12.345, test folds 12.349\n",
      "Iteration 10: RMSE - train folds 58,343.46, test folds 58,470.32\n",
      "\t\tNLL - train folds 12.343, test folds 12.347\n",
      "Iteration 20: RMSE - train folds 58,389.74, test folds 58,475.24\n",
      "\t\tNLL - train folds 12.343, test folds 12.347\n",
      "Best iterations: rmse - 18.00, 58,206.52\n",
      "\t\t nll - 14.000, 12.342\n",
      "{'col_sample': 0.6943752583889521, 'learning_rate': 0.03229833121584335, 'max_depth': 5, 'min_samples_leaf': 3, 'minibatch_frac': 0.3976457024564293}\n",
      "Iteration 0: RMSE - train folds 58,176.63, test folds 58,250.64\n",
      "\t\tNLL - train folds 12.339, test folds 12.343\n",
      "Iteration 10: RMSE - train folds 58,142.88, test folds 57,963.50\n",
      "\t\tNLL - train folds 12.339, test folds 12.336\n",
      "Iteration 20: RMSE - train folds 58,269.12, test folds 58,314.23\n",
      "\t\tNLL - train folds 12.340, test folds 12.343\n",
      "Best iterations: rmse - 12.00, 57,887.24\n",
      "\t\t nll - 12.000, 12.334\n",
      "{'col_sample': 0.6314650918408482, 'learning_rate': 0.038308947463495335, 'max_depth': 8, 'min_samples_leaf': 2, 'minibatch_frac': 0.8496231729751094}\n",
      "Iteration 0: RMSE - train folds 57,903.87, test folds 58,069.38\n",
      "\t\tNLL - train folds 12.330, test folds 12.338\n",
      "Iteration 10: RMSE - train folds 57,310.54, test folds 57,851.86\n",
      "\t\tNLL - train folds 12.311, test folds 12.328\n",
      "Iteration 20: RMSE - train folds 57,970.11, test folds 58,017.26\n",
      "\t\tNLL - train folds 12.329, test folds 12.335\n",
      "Best iterations: rmse - 10.00, 57,851.86\n",
      "\t\t nll - 10.000, 12.328\n",
      "{'col_sample': 0.6685430534813132, 'learning_rate': 0.0850571445127933, 'max_depth': 5, 'min_samples_leaf': 1, 'minibatch_frac': 0.7177951105625409}\n",
      "Iteration 0: RMSE - train folds 57,063.31, test folds 57,025.06\n",
      "\t\tNLL - train folds 12.308, test folds 12.313\n",
      "Iteration 10: RMSE - train folds 56,905.30, test folds 57,063.79\n",
      "\t\tNLL - train folds 12.305, test folds 12.314\n",
      "Iteration 20: RMSE - train folds 56,639.78, test folds 57,037.25\n",
      "\t\tNLL - train folds 12.301, test folds 12.313\n",
      "Best iterations: rmse - 19.00, 56,560.53\n",
      "\t\t nll - 19.000, 12.304\n",
      "{'col_sample': 0.700624738784116, 'learning_rate': 0.016997993265440228, 'max_depth': 5, 'min_samples_leaf': 1, 'minibatch_frac': 0.7207805082202461}\n",
      "Iteration 0: RMSE - train folds 58,583.55, test folds 58,609.25\n",
      "\t\tNLL - train folds 12.350, test folds 12.350\n",
      "Iteration 10: RMSE - train folds 58,562.85, test folds 58,610.47\n",
      "\t\tNLL - train folds 12.349, test folds 12.352\n",
      "Iteration 20: RMSE - train folds 58,511.95, test folds 58,633.17\n",
      "\t\tNLL - train folds 12.348, test folds 12.352\n",
      "Best iterations: rmse - 19.00, 58,516.96\n",
      "\t\t nll - 19.000, 12.349\n",
      "{'col_sample': 0.8186326600082205, 'learning_rate': 0.010646759543664196, 'max_depth': 4, 'min_samples_leaf': 2, 'minibatch_frac': 0.44863737747479326}\n",
      "Iteration 0: RMSE - train folds 58,818.61, test folds 58,859.82\n",
      "\t\tNLL - train folds 12.356, test folds 12.358\n",
      "Iteration 10: RMSE - train folds 58,728.83, test folds 58,742.99\n",
      "\t\tNLL - train folds 12.354, test folds 12.355\n",
      "Iteration 20: RMSE - train folds 58,737.86, test folds 58,744.14\n",
      "\t\tNLL - train folds 12.355, test folds 12.355\n",
      "Best iterations: rmse - 4.00, 58,728.25\n",
      "\t\t nll - 13.000, 12.355\n",
      "{'col_sample': 0.5818212352431953, 'learning_rate': 0.023672360788274706, 'max_depth': 6, 'min_samples_leaf': 2, 'minibatch_frac': 0.6673295021425665}\n",
      "Iteration 0: RMSE - train folds 58,441.63, test folds 58,618.54\n",
      "\t\tNLL - train folds 12.345, test folds 12.350\n",
      "Iteration 10: RMSE - train folds 58,343.25, test folds 58,416.55\n",
      "\t\tNLL - train folds 12.343, test folds 12.347\n",
      "Iteration 20: RMSE - train folds 58,322.22, test folds 58,545.21\n",
      "\t\tNLL - train folds 12.343, test folds 12.349\n",
      "Iteration 30: RMSE - train folds 58,202.30, test folds 58,325.80\n",
      "\t\tNLL - train folds 12.338, test folds 12.345\n",
      "Iteration 40: RMSE - train folds 58,441.43, test folds 58,462.66\n",
      "\t\tNLL - train folds 12.346, test folds 12.348\n",
      "Best iterations: rmse - 34.00, 58,216.34\n",
      "\t\t nll - 26.000, 12.341\n",
      "{'col_sample': 0.6943752583889521, 'learning_rate': 0.03229833121584335, 'max_depth': 5, 'min_samples_leaf': 3, 'minibatch_frac': 0.3976457024564293}\n",
      "Iteration 0: RMSE - train folds 58,253.90, test folds 58,106.77\n",
      "\t\tNLL - train folds 12.341, test folds 12.340\n",
      "Iteration 10: RMSE - train folds 58,188.10, test folds 58,262.79\n",
      "\t\tNLL - train folds 12.339, test folds 12.342\n",
      "Iteration 20: RMSE - train folds 58,286.60, test folds 58,282.54\n",
      "\t\tNLL - train folds 12.343, test folds 12.343\n",
      "Iteration 30: RMSE - train folds 58,320.26, test folds 58,362.45\n",
      "\t\tNLL - train folds 12.342, test folds 12.345\n",
      "Best iterations: rmse - 22.00, 58,003.34\n",
      "\t\t nll - 22.000, 12.336\n",
      "{'col_sample': 0.6314650918408482, 'learning_rate': 0.038308947463495335, 'max_depth': 8, 'min_samples_leaf': 2, 'minibatch_frac': 0.8496231729751094}\n",
      "Iteration 0: RMSE - train folds 57,905.97, test folds 58,005.57\n",
      "\t\tNLL - train folds 12.330, test folds 12.336\n",
      "Iteration 10: RMSE - train folds 57,989.67, test folds 58,050.60\n",
      "\t\tNLL - train folds 12.330, test folds 12.336\n",
      "Best iterations: rmse - 1.00, 57,992.80\n",
      "\t\t nll - 1.000, 12.334\n",
      "{'col_sample': 0.6685430534813132, 'learning_rate': 0.0850571445127933, 'max_depth': 5, 'min_samples_leaf': 1, 'minibatch_frac': 0.7177951105625409}\n",
      "Iteration 0: RMSE - train folds 57,118.13, test folds 57,496.62\n",
      "\t\tNLL - train folds 12.307, test folds 12.320\n",
      "Iteration 10: RMSE - train folds 56,786.01, test folds 57,293.11\n",
      "\t\tNLL - train folds 12.303, test folds 12.317\n",
      "Best iterations: rmse - 1.00, 56,665.54\n",
      "\t\t nll - 1.000, 12.307\n",
      "{'col_sample': 0.700624738784116, 'learning_rate': 0.016997993265440228, 'max_depth': 5, 'min_samples_leaf': 1, 'minibatch_frac': 0.7207805082202461}\n",
      "Iteration 0: RMSE - train folds 58,580.44, test folds 58,597.00\n",
      "\t\tNLL - train folds 12.349, test folds 12.351\n",
      "Iteration 10: RMSE - train folds 58,542.13, test folds 58,498.30\n",
      "\t\tNLL - train folds 12.349, test folds 12.349\n",
      "Iteration 20: RMSE - train folds 58,577.92, test folds 58,637.57\n",
      "\t\tNLL - train folds 12.349, test folds 12.352\n",
      "Best iterations: rmse - 10.00, 58,498.30\n",
      "\t\t nll - 10.000, 12.349\n",
      "{'col_sample': 0.8186326600082205, 'learning_rate': 0.010646759543664196, 'max_depth': 4, 'min_samples_leaf': 2, 'minibatch_frac': 0.44863737747479326}\n",
      "Iteration 0: RMSE - train folds 58,739.71, test folds 58,759.18\n",
      "\t\tNLL - train folds 12.355, test folds 12.355\n",
      "Iteration 10: RMSE - train folds 58,727.31, test folds 58,751.92\n",
      "\t\tNLL - train folds 12.355, test folds 12.355\n",
      "Iteration 20: RMSE - train folds 58,716.27, test folds 58,732.73\n",
      "\t\tNLL - train folds 12.355, test folds 12.356\n",
      "Iteration 30: RMSE - train folds 58,760.77, test folds 58,797.99\n",
      "\t\tNLL - train folds 12.355, test folds 12.357\n",
      "Best iterations: rmse - 20.00, 58,732.73\n",
      "\t\t nll - 10.000, 12.355\n",
      "{'col_sample': 0.5818212352431953, 'learning_rate': 0.023672360788274706, 'max_depth': 6, 'min_samples_leaf': 2, 'minibatch_frac': 0.6673295021425665}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: RMSE - train folds 58,384.50, test folds 58,471.03\n",
      "\t\tNLL - train folds 12.345, test folds 12.348\n",
      "Iteration 10: RMSE - train folds 58,107.73, test folds 58,306.52\n",
      "\t\tNLL - train folds 12.337, test folds 12.344\n",
      "Best iterations: rmse - 8.00, 58,229.56\n",
      "\t\t nll - 8.000, 12.340\n",
      "{'col_sample': 0.6943752583889521, 'learning_rate': 0.03229833121584335, 'max_depth': 5, 'min_samples_leaf': 3, 'minibatch_frac': 0.3976457024564293}\n",
      "Iteration 0: RMSE - train folds 58,201.74, test folds 58,261.16\n",
      "\t\tNLL - train folds 12.339, test folds 12.342\n",
      "Iteration 10: RMSE - train folds 58,252.29, test folds 58,437.05\n",
      "\t\tNLL - train folds 12.342, test folds 12.346\n",
      "Iteration 20: RMSE - train folds 58,164.31, test folds 58,064.97\n",
      "\t\tNLL - train folds 12.340, test folds 12.338\n",
      "Best iterations: rmse - 12.00, 58,027.61\n",
      "\t\t nll - 12.000, 12.336\n",
      "{'col_sample': 0.6314650918408482, 'learning_rate': 0.038308947463495335, 'max_depth': 8, 'min_samples_leaf': 2, 'minibatch_frac': 0.8496231729751094}\n",
      "Iteration 0: RMSE - train folds 58,032.76, test folds 58,077.72\n",
      "\t\tNLL - train folds 12.331, test folds 12.336\n",
      "Iteration 10: RMSE - train folds 57,932.11, test folds 58,134.82\n",
      "\t\tNLL - train folds 12.329, test folds 12.337\n",
      "Iteration 20: RMSE - train folds 57,991.49, test folds 58,041.07\n",
      "\t\tNLL - train folds 12.330, test folds 12.336\n",
      "Best iterations: rmse - 19.00, 57,771.82\n",
      "\t\t nll - 19.000, 12.328\n",
      "{'col_sample': 0.6685430534813132, 'learning_rate': 0.0850571445127933, 'max_depth': 5, 'min_samples_leaf': 1, 'minibatch_frac': 0.7177951105625409}\n",
      "Iteration 0: RMSE - train folds 58,006.15, test folds 57,808.80\n",
      "\t\tNLL - train folds 12.326, test folds 12.326\n",
      "Iteration 10: RMSE - train folds 57,092.67, test folds 57,457.20\n",
      "\t\tNLL - train folds 12.307, test folds 12.323\n",
      "Best iterations: rmse - 2.00, 56,663.32\n",
      "\t\t nll - 2.000, 12.303\n",
      "{'col_sample': 0.700624738784116, 'learning_rate': 0.016997993265440228, 'max_depth': 5, 'min_samples_leaf': 1, 'minibatch_frac': 0.7207805082202461}\n",
      "Iteration 0: RMSE - train folds 58,764.61, test folds 58,687.32\n",
      "\t\tNLL - train folds 12.354, test folds 12.354\n",
      "Iteration 10: RMSE - train folds 58,610.67, test folds 58,727.68\n",
      "\t\tNLL - train folds 12.349, test folds 12.355\n",
      "Best iterations: rmse - 2.00, 58,489.04\n",
      "\t\t nll - 2.000, 12.349\n",
      "{'col_sample': 0.8186326600082205, 'learning_rate': 0.010646759543664196, 'max_depth': 4, 'min_samples_leaf': 2, 'minibatch_frac': 0.44863737747479326}\n",
      "Iteration 0: RMSE - train folds 58,791.04, test folds 58,798.15\n",
      "\t\tNLL - train folds 12.356, test folds 12.357\n",
      "Iteration 10: RMSE - train folds 58,730.21, test folds 58,803.89\n",
      "\t\tNLL - train folds 12.353, test folds 12.356\n",
      "Best iterations: rmse - 1.00, 58,778.45\n",
      "\t\t nll - 1.000, 12.356\n",
      "{'col_sample': 0.5818212352431953, 'learning_rate': 0.023672360788274706, 'max_depth': 6, 'min_samples_leaf': 2, 'minibatch_frac': 0.6673295021425665}\n",
      "Iteration 0: RMSE - train folds 58,512.38, test folds 58,599.73\n",
      "\t\tNLL - train folds 12.346, test folds 12.350\n",
      "Iteration 10: RMSE - train folds 58,414.04, test folds 58,397.61\n",
      "\t\tNLL - train folds 12.344, test folds 12.346\n",
      "Best iterations: rmse - 9.00, 58,150.44\n",
      "\t\t nll - 9.000, 12.338\n",
      "{'col_sample': 0.6943752583889521, 'learning_rate': 0.03229833121584335, 'max_depth': 5, 'min_samples_leaf': 3, 'minibatch_frac': 0.3976457024564293}\n",
      "Iteration 0: RMSE - train folds 58,504.73, test folds 58,392.89\n",
      "\t\tNLL - train folds 12.347, test folds 12.347\n",
      "Iteration 10: RMSE - train folds 58,381.35, test folds 58,545.65\n",
      "\t\tNLL - train folds 12.343, test folds 12.349\n",
      "Best iterations: rmse - 2.00, 58,172.19\n",
      "\t\t nll - 2.000, 12.337\n",
      "{'col_sample': 0.6314650918408482, 'learning_rate': 0.038308947463495335, 'max_depth': 8, 'min_samples_leaf': 2, 'minibatch_frac': 0.8496231729751094}\n",
      "Iteration 0: RMSE - train folds 57,986.64, test folds 58,107.00\n",
      "\t\tNLL - train folds 12.330, test folds 12.338\n",
      "Iteration 10: RMSE - train folds 57,919.42, test folds 58,019.96\n",
      "\t\tNLL - train folds 12.329, test folds 12.336\n",
      "Best iterations: rmse - 3.00, 57,559.03\n",
      "\t\t nll - 3.000, 12.323\n",
      "{'col_sample': 0.6685430534813132, 'learning_rate': 0.0850571445127933, 'max_depth': 5, 'min_samples_leaf': 1, 'minibatch_frac': 0.7177951105625409}\n",
      "Iteration 0: RMSE - train folds 56,814.08, test folds 57,317.53\n",
      "\t\tNLL - train folds 12.301, test folds 12.317\n",
      "Iteration 10: RMSE - train folds 56,635.03, test folds 56,907.75\n",
      "\t\tNLL - train folds 12.296, test folds 12.309\n",
      "Best iterations: rmse - 5.00, 56,514.57\n",
      "\t\t nll - 7.000, 12.300\n",
      "{'col_sample': 0.700624738784116, 'learning_rate': 0.016997993265440228, 'max_depth': 5, 'min_samples_leaf': 1, 'minibatch_frac': 0.7207805082202461}\n",
      "Iteration 0: RMSE - train folds 58,540.51, test folds 58,662.27\n",
      "\t\tNLL - train folds 12.348, test folds 12.353\n",
      "Iteration 10: RMSE - train folds 58,486.39, test folds 58,579.33\n",
      "\t\tNLL - train folds 12.346, test folds 12.350\n",
      "Iteration 20: RMSE - train folds 58,623.71, test folds 58,669.16\n",
      "\t\tNLL - train folds 12.350, test folds 12.352\n",
      "Best iterations: rmse - 9.00, 58,556.98\n",
      "\t\t nll - 16.000, 12.349\n",
      "{'col_sample': 0.8186326600082205, 'learning_rate': 0.010646759543664196, 'max_depth': 4, 'min_samples_leaf': 2, 'minibatch_frac': 0.44863737747479326}\n",
      "Iteration 0: RMSE - train folds 58,780.41, test folds 58,830.86\n",
      "\t\tNLL - train folds 12.355, test folds 12.357\n",
      "Iteration 10: RMSE - train folds 58,740.67, test folds 58,798.01\n",
      "\t\tNLL - train folds 12.355, test folds 12.357\n",
      "Iteration 20: RMSE - train folds 58,741.56, test folds 58,735.61\n",
      "\t\tNLL - train folds 12.355, test folds 12.355\n",
      "Best iterations: rmse - 17.00, 58,665.76\n",
      "\t\t nll - 17.000, 12.354\n",
      "{'col_sample': 0.5818212352431953, 'learning_rate': 0.023672360788274706, 'max_depth': 6, 'min_samples_leaf': 2, 'minibatch_frac': 0.6673295021425665}\n",
      "Iteration 0: RMSE - train folds 58,379.36, test folds 58,438.08\n",
      "\t\tNLL - train folds 12.343, test folds 12.348\n",
      "Iteration 10: RMSE - train folds 58,187.43, test folds 58,306.40\n",
      "\t\tNLL - train folds 12.338, test folds 12.343\n",
      "Iteration 20: RMSE - train folds 58,365.36, test folds 58,325.03\n",
      "\t\tNLL - train folds 12.344, test folds 12.343\n",
      "Best iterations: rmse - 14.00, 58,180.09\n",
      "\t\t nll - 14.000, 12.339\n",
      "{'col_sample': 0.6943752583889521, 'learning_rate': 0.03229833121584335, 'max_depth': 5, 'min_samples_leaf': 3, 'minibatch_frac': 0.3976457024564293}\n",
      "Iteration 0: RMSE - train folds 58,279.10, test folds 58,235.89\n",
      "\t\tNLL - train folds 12.341, test folds 12.342\n",
      "Iteration 10: RMSE - train folds 58,357.14, test folds 58,368.84\n",
      "\t\tNLL - train folds 12.345, test folds 12.345\n",
      "Best iterations: rmse - 7.00, 58,223.27\n",
      "\t\t nll - 7.000, 12.341\n",
      "{'col_sample': 0.6314650918408482, 'learning_rate': 0.038308947463495335, 'max_depth': 8, 'min_samples_leaf': 2, 'minibatch_frac': 0.8496231729751094}\n",
      "Iteration 0: RMSE - train folds 58,086.09, test folds 58,339.38\n",
      "\t\tNLL - train folds 12.332, test folds 12.341\n",
      "Iteration 10: RMSE - train folds 57,944.40, test folds 58,180.16\n",
      "\t\tNLL - train folds 12.330, test folds 12.338\n",
      "Best iterations: rmse - 5.00, 57,733.56\n",
      "\t\t nll - 3.000, 12.326\n",
      "{'col_sample': 0.6685430534813132, 'learning_rate': 0.0850571445127933, 'max_depth': 5, 'min_samples_leaf': 1, 'minibatch_frac': 0.7177951105625409}\n",
      "Iteration 0: RMSE - train folds 56,583.20, test folds 57,965.16\n",
      "\t\tNLL - train folds 12.302, test folds 12.322\n",
      "Iteration 10: RMSE - train folds 56,354.21, test folds 56,943.65\n",
      "\t\tNLL - train folds 12.291, test folds 12.307\n",
      "Best iterations: rmse - 8.00, 56,530.54\n",
      "\t\t nll - 8.000, 12.303\n",
      "{'col_sample': 0.700624738784116, 'learning_rate': 0.016997993265440228, 'max_depth': 5, 'min_samples_leaf': 1, 'minibatch_frac': 0.7207805082202461}\n",
      "Iteration 0: RMSE - train folds 58,676.96, test folds 58,728.05\n",
      "\t\tNLL - train folds 12.351, test folds 12.355\n",
      "Iteration 10: RMSE - train folds 58,475.99, test folds 58,591.55\n",
      "\t\tNLL - train folds 12.346, test folds 12.350\n",
      "Best iterations: rmse - 8.00, 58,483.66\n",
      "\t\t nll - 8.000, 12.349\n",
      "{'col_sample': 0.8186326600082205, 'learning_rate': 0.010646759543664196, 'max_depth': 4, 'min_samples_leaf': 2, 'minibatch_frac': 0.44863737747479326}\n",
      "Iteration 0: RMSE - train folds 58,718.70, test folds 58,777.64\n",
      "\t\tNLL - train folds 12.353, test folds 12.356\n",
      "Iteration 10: RMSE - train folds 58,745.01, test folds 58,803.33\n",
      "\t\tNLL - train folds 12.355, test folds 12.357\n",
      "Iteration 20: RMSE - train folds 58,778.85, test folds 58,787.84\n",
      "\t\tNLL - train folds 12.356, test folds 12.357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best iterations: rmse - 18.00, 58,680.25\n",
      "\t\t nll - 18.000, 12.353\n",
      "{'col_sample': 0.5818212352431953, 'learning_rate': 0.023672360788274706, 'max_depth': 6, 'min_samples_leaf': 2, 'minibatch_frac': 0.6673295021425665}\n",
      "Iteration 0: RMSE - train folds 58,337.78, test folds 58,462.41\n",
      "\t\tNLL - train folds 12.344, test folds 12.348\n",
      "Iteration 10: RMSE - train folds 58,377.95, test folds 58,515.42\n",
      "\t\tNLL - train folds 12.344, test folds 12.348\n",
      "Iteration 20: RMSE - train folds 58,402.98, test folds 58,520.99\n",
      "\t\tNLL - train folds 12.343, test folds 12.349\n",
      "Iteration 30: RMSE - train folds 58,395.69, test folds 58,450.47\n",
      "\t\tNLL - train folds 12.343, test folds 12.347\n",
      "Best iterations: rmse - 21.00, 58,153.18\n",
      "\t\t nll - 21.000, 12.339\n",
      "{'col_sample': 0.6943752583889521, 'learning_rate': 0.03229833121584335, 'max_depth': 5, 'min_samples_leaf': 3, 'minibatch_frac': 0.3976457024564293}\n",
      "Iteration 0: RMSE - train folds 58,372.61, test folds 58,415.36\n",
      "\t\tNLL - train folds 12.343, test folds 12.347\n",
      "Iteration 10: RMSE - train folds 58,069.86, test folds 58,011.47\n",
      "\t\tNLL - train folds 12.335, test folds 12.336\n",
      "Iteration 20: RMSE - train folds 58,142.58, test folds 58,226.29\n",
      "\t\tNLL - train folds 12.339, test folds 12.343\n",
      "Best iterations: rmse - 10.00, 58,011.47\n",
      "\t\t nll - 10.000, 12.336\n",
      "{'col_sample': 0.6314650918408482, 'learning_rate': 0.038308947463495335, 'max_depth': 8, 'min_samples_leaf': 2, 'minibatch_frac': 0.8496231729751094}\n",
      "Iteration 0: RMSE - train folds 58,039.56, test folds 58,168.21\n",
      "\t\tNLL - train folds 12.332, test folds 12.339\n",
      "Iteration 10: RMSE - train folds 57,918.79, test folds 58,018.41\n",
      "\t\tNLL - train folds 12.329, test folds 12.336\n",
      "Iteration 20: RMSE - train folds 57,968.43, test folds 58,110.52\n",
      "\t\tNLL - train folds 12.330, test folds 12.338\n",
      "Iteration 30: RMSE - train folds 57,963.57, test folds 57,986.55\n",
      "\t\tNLL - train folds 12.329, test folds 12.335\n",
      "Best iterations: rmse - 24.00, 57,858.70\n",
      "\t\t nll - 14.000, 12.331\n",
      "{'col_sample': 0.6685430534813132, 'learning_rate': 0.0850571445127933, 'max_depth': 5, 'min_samples_leaf': 1, 'minibatch_frac': 0.7177951105625409}\n",
      "Iteration 0: RMSE - train folds 56,821.13, test folds 57,158.28\n",
      "\t\tNLL - train folds 12.304, test folds 12.315\n",
      "Iteration 10: RMSE - train folds 57,029.89, test folds 56,629.71\n",
      "\t\tNLL - train folds 12.309, test folds 12.306\n",
      "Iteration 20: RMSE - train folds 57,083.68, test folds 57,025.04\n",
      "\t\tNLL - train folds 12.309, test folds 12.314\n",
      "Best iterations: rmse - 14.00, 56,265.28\n",
      "\t\t nll - 14.000, 12.295\n",
      "{'col_sample': 0.700624738784116, 'learning_rate': 0.016997993265440228, 'max_depth': 5, 'min_samples_leaf': 1, 'minibatch_frac': 0.7207805082202461}\n",
      "Iteration 0: RMSE - train folds 58,554.69, test folds 58,641.49\n",
      "\t\tNLL - train folds 12.349, test folds 12.353\n",
      "Iteration 10: RMSE - train folds 58,496.63, test folds 58,478.73\n",
      "\t\tNLL - train folds 12.349, test folds 12.349\n",
      "Iteration 20: RMSE - train folds 58,593.93, test folds 58,719.64\n",
      "\t\tNLL - train folds 12.350, test folds 12.354\n",
      "Best iterations: rmse - 18.00, 58,429.67\n",
      "\t\t nll - 14.000, 12.347\n",
      "{'col_sample': 0.8186326600082205, 'learning_rate': 0.010646759543664196, 'max_depth': 4, 'min_samples_leaf': 2, 'minibatch_frac': 0.44863737747479326}\n",
      "Iteration 0: RMSE - train folds 58,708.70, test folds 58,763.31\n",
      "\t\tNLL - train folds 12.354, test folds 12.356\n",
      "Iteration 10: RMSE - train folds 58,721.43, test folds 58,785.08\n",
      "\t\tNLL - train folds 12.354, test folds 12.357\n",
      "Iteration 20: RMSE - train folds 58,769.59, test folds 58,858.26\n",
      "\t\tNLL - train folds 12.355, test folds 12.358\n",
      "Best iterations: rmse - 16.00, 58,682.79\n",
      "\t\t nll - 16.000, 12.353\n",
      "{'col_sample': 0.5818212352431953, 'learning_rate': 0.023672360788274706, 'max_depth': 6, 'min_samples_leaf': 2, 'minibatch_frac': 0.6673295021425665}\n",
      "Iteration 0: RMSE - train folds 58,355.70, test folds 58,486.12\n",
      "\t\tNLL - train folds 12.344, test folds 12.349\n",
      "Iteration 10: RMSE - train folds 58,324.04, test folds 58,430.82\n",
      "\t\tNLL - train folds 12.344, test folds 12.348\n",
      "Best iterations: rmse - 2.00, 57,993.74\n",
      "\t\t nll - 2.000, 12.337\n",
      "{'col_sample': 0.6943752583889521, 'learning_rate': 0.03229833121584335, 'max_depth': 5, 'min_samples_leaf': 3, 'minibatch_frac': 0.3976457024564293}\n",
      "Iteration 0: RMSE - train folds 58,123.63, test folds 58,228.33\n",
      "\t\tNLL - train folds 12.339, test folds 12.342\n",
      "Iteration 10: RMSE - train folds 58,211.26, test folds 58,321.57\n",
      "\t\tNLL - train folds 12.343, test folds 12.346\n",
      "Best iterations: rmse - 2.00, 57,937.27\n",
      "\t\t nll - 2.000, 12.336\n",
      "{'col_sample': 0.6314650918408482, 'learning_rate': 0.038308947463495335, 'max_depth': 8, 'min_samples_leaf': 2, 'minibatch_frac': 0.8496231729751094}\n",
      "Iteration 0: RMSE - train folds 58,005.95, test folds 57,993.50\n",
      "\t\tNLL - train folds 12.331, test folds 12.336\n",
      "Iteration 10: RMSE - train folds 57,964.51, test folds 58,048.45\n",
      "\t\tNLL - train folds 12.332, test folds 12.337\n",
      "Best iterations: rmse - 2.00, 57,584.39\n",
      "\t\t nll - 2.000, 12.324\n",
      "{'col_sample': 0.6685430534813132, 'learning_rate': 0.0850571445127933, 'max_depth': 5, 'min_samples_leaf': 1, 'minibatch_frac': 0.7177951105625409}\n",
      "Iteration 0: RMSE - train folds 56,926.03, test folds 57,151.00\n",
      "\t\tNLL - train folds 12.310, test folds 12.319\n",
      "Iteration 10: RMSE - train folds 56,956.98, test folds 57,305.41\n",
      "\t\tNLL - train folds 12.305, test folds 12.317\n",
      "Best iterations: rmse - 7.00, 56,724.05\n",
      "\t\t nll - 7.000, 12.302\n",
      "{'col_sample': 0.700624738784116, 'learning_rate': 0.016997993265440228, 'max_depth': 5, 'min_samples_leaf': 1, 'minibatch_frac': 0.7207805082202461}\n",
      "Iteration 0: RMSE - train folds 58,575.61, test folds 58,653.09\n",
      "\t\tNLL - train folds 12.351, test folds 12.354\n",
      "Iteration 10: RMSE - train folds 58,556.87, test folds 58,642.13\n",
      "\t\tNLL - train folds 12.349, test folds 12.352\n",
      "Best iterations: rmse - 4.00, 58,515.39\n",
      "\t\t nll - 4.000, 12.347\n",
      "{'col_sample': 0.8186326600082205, 'learning_rate': 0.010646759543664196, 'max_depth': 4, 'min_samples_leaf': 2, 'minibatch_frac': 0.44863737747479326}\n",
      "Iteration 0: RMSE - train folds 58,699.77, test folds 58,812.94\n",
      "\t\tNLL - train folds 12.353, test folds 12.357\n",
      "Iteration 10: RMSE - train folds 58,752.22, test folds 58,820.48\n",
      "\t\tNLL - train folds 12.355, test folds 12.357\n",
      "Iteration 20: RMSE - train folds 58,733.23, test folds 58,779.57\n",
      "\t\tNLL - train folds 12.353, test folds 12.356\n",
      "Best iterations: rmse - 19.00, 58,697.22\n",
      "\t\t nll - 19.000, 12.354\n",
      "{'col_sample': 0.5818212352431953, 'learning_rate': 0.023672360788274706, 'max_depth': 6, 'min_samples_leaf': 2, 'minibatch_frac': 0.6673295021425665}\n",
      "Iteration 0: RMSE - train folds 58,372.08, test folds 58,562.66\n",
      "\t\tNLL - train folds 12.345, test folds 12.350\n",
      "Iteration 10: RMSE - train folds 58,461.53, test folds 58,576.39\n",
      "\t\tNLL - train folds 12.346, test folds 12.349\n",
      "Best iterations: rmse - 1.00, 58,286.77\n",
      "\t\t nll - 9.000, 12.342\n",
      "{'col_sample': 0.6943752583889521, 'learning_rate': 0.03229833121584335, 'max_depth': 5, 'min_samples_leaf': 3, 'minibatch_frac': 0.3976457024564293}\n",
      "Iteration 0: RMSE - train folds 58,240.09, test folds 58,468.00\n",
      "\t\tNLL - train folds 12.342, test folds 12.348\n",
      "Iteration 10: RMSE - train folds 58,217.46, test folds 58,346.32\n",
      "\t\tNLL - train folds 12.340, test folds 12.345\n",
      "Iteration 20: RMSE - train folds 58,096.32, test folds 58,220.66\n",
      "\t\tNLL - train folds 12.336, test folds 12.341\n",
      "Iteration 30: RMSE - train folds 58,343.83, test folds 58,381.00\n",
      "\t\tNLL - train folds 12.343, test folds 12.345\n",
      "Best iterations: rmse - 23.00, 58,033.22\n",
      "\t\t nll - 21.000, 12.337\n",
      "{'col_sample': 0.6314650918408482, 'learning_rate': 0.038308947463495335, 'max_depth': 8, 'min_samples_leaf': 2, 'minibatch_frac': 0.8496231729751094}\n",
      "Iteration 0: RMSE - train folds 57,928.10, test folds 58,068.66\n",
      "\t\tNLL - train folds 12.330, test folds 12.338\n",
      "Iteration 10: RMSE - train folds 57,603.54, test folds 57,883.59\n",
      "\t\tNLL - train folds 12.318, test folds 12.330\n",
      "Best iterations: rmse - 9.00, 57,781.79\n",
      "\t\t nll - 9.000, 12.330\n",
      "{'col_sample': 0.6685430534813132, 'learning_rate': 0.0850571445127933, 'max_depth': 5, 'min_samples_leaf': 1, 'minibatch_frac': 0.7177951105625409}\n",
      "Iteration 0: RMSE - train folds 57,144.79, test folds 56,648.88\n",
      "\t\tNLL - train folds 12.309, test folds 12.304\n",
      "Iteration 10: RMSE - train folds 56,943.80, test folds 57,470.35\n",
      "\t\tNLL - train folds 12.305, test folds 12.314\n",
      "Iteration 20: RMSE - train folds 56,929.35, test folds 57,761.77\n",
      "\t\tNLL - train folds 12.303, test folds 12.324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30: RMSE - train folds 57,373.44, test folds 57,403.17\n",
      "\t\tNLL - train folds 12.315, test folds 12.322\n",
      "Iteration 40: RMSE - train folds 57,133.76, test folds 57,734.55\n",
      "\t\tNLL - train folds 12.308, test folds 12.321\n",
      "Best iterations: rmse - 31.00, 56,559.63\n",
      "\t\t nll - 29.000, 12.294\n",
      "{'col_sample': 0.700624738784116, 'learning_rate': 0.016997993265440228, 'max_depth': 5, 'min_samples_leaf': 1, 'minibatch_frac': 0.7207805082202461}\n",
      "Iteration 0: RMSE - train folds 58,331.47, test folds 58,482.67\n",
      "\t\tNLL - train folds 12.342, test folds 12.347\n",
      "Iteration 10: RMSE - train folds 58,548.13, test folds 58,485.92\n",
      "\t\tNLL - train folds 12.349, test folds 12.349\n",
      "Iteration 20: RMSE - train folds 58,542.19, test folds 58,712.07\n",
      "\t\tNLL - train folds 12.348, test folds 12.353\n",
      "Iteration 30: RMSE - train folds 58,712.15, test folds 58,717.18\n",
      "\t\tNLL - train folds 12.352, test folds 12.355\n",
      "Best iterations: rmse - 29.00, 58,395.67\n",
      "\t\t nll - 29.000, 12.344\n",
      "{'col_sample': 0.8186326600082205, 'learning_rate': 0.010646759543664196, 'max_depth': 4, 'min_samples_leaf': 2, 'minibatch_frac': 0.44863737747479326}\n",
      "Iteration 0: RMSE - train folds 58,827.15, test folds 58,819.07\n",
      "\t\tNLL - train folds 12.357, test folds 12.358\n",
      "Iteration 10: RMSE - train folds 58,750.11, test folds 58,774.82\n",
      "\t\tNLL - train folds 12.355, test folds 12.356\n",
      "Best iterations: rmse - 2.00, 58,738.58\n",
      "\t\t nll - 6.000, 12.355\n",
      "{'col_sample': 0.5818212352431953, 'learning_rate': 0.023672360788274706, 'max_depth': 6, 'min_samples_leaf': 2, 'minibatch_frac': 0.6673295021425665}\n",
      "Iteration 0: RMSE - train folds 58,358.32, test folds 58,446.12\n",
      "\t\tNLL - train folds 12.343, test folds 12.347\n",
      "Iteration 10: RMSE - train folds 58,238.78, test folds 58,365.96\n",
      "\t\tNLL - train folds 12.341, test folds 12.345\n",
      "Best iterations: rmse - 1.00, 58,179.70\n",
      "\t\t nll - 1.000, 12.338\n",
      "{'col_sample': 0.6943752583889521, 'learning_rate': 0.03229833121584335, 'max_depth': 5, 'min_samples_leaf': 3, 'minibatch_frac': 0.3976457024564293}\n",
      "Iteration 0: RMSE - train folds 58,544.99, test folds 58,177.96\n",
      "\t\tNLL - train folds 12.349, test folds 12.341\n",
      "Iteration 10: RMSE - train folds 58,336.84, test folds 58,386.82\n",
      "\t\tNLL - train folds 12.344, test folds 12.347\n",
      "Best iterations: rmse - 3.00, 58,114.11\n",
      "\t\t nll - 3.000, 12.339\n",
      "{'col_sample': 0.6314650918408482, 'learning_rate': 0.038308947463495335, 'max_depth': 8, 'min_samples_leaf': 2, 'minibatch_frac': 0.8496231729751094}\n",
      "Iteration 0: RMSE - train folds 57,948.33, test folds 58,193.18\n",
      "\t\tNLL - train folds 12.330, test folds 12.339\n",
      "Iteration 10: RMSE - train folds 57,892.97, test folds 58,005.93\n",
      "\t\tNLL - train folds 12.328, test folds 12.334\n",
      "Iteration 20: RMSE - train folds 57,892.81, test folds 58,041.89\n",
      "\t\tNLL - train folds 12.328, test folds 12.336\n",
      "Best iterations: rmse - 12.00, 57,742.04\n",
      "\t\t nll - 12.000, 12.327\n",
      "{'col_sample': 0.6685430534813132, 'learning_rate': 0.0850571445127933, 'max_depth': 5, 'min_samples_leaf': 1, 'minibatch_frac': 0.7177951105625409}\n",
      "Iteration 0: RMSE - train folds 55,902.77, test folds 56,875.78\n",
      "\t\tNLL - train folds 12.282, test folds 12.300\n",
      "Iteration 10: RMSE - train folds 56,152.00, test folds 56,696.65\n",
      "\t\tNLL - train folds 12.288, test folds 12.305\n",
      "Iteration 20: RMSE - train folds 59,624.08, test folds 57,243.50\n",
      "\t\tNLL - train folds 12.296, test folds 12.309\n",
      "Best iterations: rmse - 15.00, 56,516.31\n",
      "\t\t nll - 5.000, 12.300\n",
      "{'col_sample': 0.700624738784116, 'learning_rate': 0.016997993265440228, 'max_depth': 5, 'min_samples_leaf': 1, 'minibatch_frac': 0.7207805082202461}\n",
      "Iteration 0: RMSE - train folds 58,344.12, test folds 58,481.89\n",
      "\t\tNLL - train folds 12.343, test folds 12.347\n",
      "Iteration 10: RMSE - train folds 58,397.47, test folds 58,514.58\n",
      "\t\tNLL - train folds 12.344, test folds 12.349\n",
      "Best iterations: rmse - 5.00, 58,370.53\n",
      "\t\t nll - 5.000, 12.345\n",
      "{'col_sample': 0.8186326600082205, 'learning_rate': 0.010646759543664196, 'max_depth': 4, 'min_samples_leaf': 2, 'minibatch_frac': 0.44863737747479326}\n",
      "Iteration 0: RMSE - train folds 58,843.30, test folds 58,797.81\n",
      "\t\tNLL - train folds 12.357, test folds 12.356\n",
      "Iteration 10: RMSE - train folds 58,758.75, test folds 58,819.83\n",
      "\t\tNLL - train folds 12.355, test folds 12.357\n",
      "Iteration 20: RMSE - train folds 58,737.08, test folds 58,819.09\n",
      "\t\tNLL - train folds 12.355, test folds 12.357\n",
      "Best iterations: rmse - 18.00, 58,728.34\n",
      "\t\t nll - 14.000, 12.354\n",
      "{'col_sample': 0.5818212352431953, 'learning_rate': 0.023672360788274706, 'max_depth': 6, 'min_samples_leaf': 2, 'minibatch_frac': 0.6673295021425665}\n",
      "Iteration 0: RMSE - train folds 58,486.93, test folds 58,480.89\n",
      "\t\tNLL - train folds 12.346, test folds 12.348\n",
      "Iteration 10: RMSE - train folds 58,534.15, test folds 58,588.69\n",
      "\t\tNLL - train folds 12.347, test folds 12.351\n",
      "Best iterations: rmse - 2.00, 58,190.02\n",
      "\t\t nll - 2.000, 12.340\n",
      "{'col_sample': 0.6943752583889521, 'learning_rate': 0.03229833121584335, 'max_depth': 5, 'min_samples_leaf': 3, 'minibatch_frac': 0.3976457024564293}\n",
      "Iteration 0: RMSE - train folds 58,236.14, test folds 58,270.96\n",
      "\t\tNLL - train folds 12.342, test folds 12.343\n",
      "Iteration 10: RMSE - train folds 58,325.46, test folds 58,400.27\n",
      "\t\tNLL - train folds 12.343, test folds 12.346\n",
      "Best iterations: rmse - 5.00, 57,940.90\n",
      "\t\t nll - 5.000, 12.335\n",
      "{'col_sample': 0.6314650918408482, 'learning_rate': 0.038308947463495335, 'max_depth': 8, 'min_samples_leaf': 2, 'minibatch_frac': 0.8496231729751094}\n",
      "Iteration 0: RMSE - train folds 57,936.57, test folds 58,093.19\n",
      "\t\tNLL - train folds 12.330, test folds 12.337\n",
      "Iteration 10: RMSE - train folds 58,076.49, test folds 58,306.52\n",
      "\t\tNLL - train folds 12.333, test folds 12.342\n",
      "Iteration 20: RMSE - train folds 58,058.97, test folds 58,199.85\n",
      "\t\tNLL - train folds 12.332, test folds 12.339\n",
      "Best iterations: rmse - 19.00, 57,854.99\n",
      "\t\t nll - 19.000, 12.330\n"
     ]
    }
   ],
   "source": [
    "for modelrun in range(10):\n",
    "    best_nll_score, wmape, nll_col_sample, nll_learning_rate, nll_max_depth, nll_min_samples_leaf, nll_minibatch_frac, \\\n",
    "    nll_n_estimators, house_sel_90_df, house_sel_80_df, house_sel_70_df, intervals_percent_df, homes_df = \\\n",
    "    random_search(\n",
    "        X, fold_data, best_nll_score, wmape, nll_col_sample, nll_learning_rate, nll_max_depth, nll_min_samples_leaf, \\\n",
    "        nll_minibatch_frac, nll_n_estimators, house_sel_90_df, house_sel_80_df, house_sel_70_df, intervals_percent_df, \\\n",
    "        seeds, modelrun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9da59a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Middle_90%</th>\n",
       "      <th>Middle_80%</th>\n",
       "      <th>Middle_70%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96.203438</td>\n",
       "      <td>88.323782</td>\n",
       "      <td>79.154728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95.988539</td>\n",
       "      <td>92.084527</td>\n",
       "      <td>87.285100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89.756447</td>\n",
       "      <td>79.763610</td>\n",
       "      <td>70.702006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92.048711</td>\n",
       "      <td>81.769341</td>\n",
       "      <td>72.206304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96.704871</td>\n",
       "      <td>90.186246</td>\n",
       "      <td>81.411175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>97.063037</td>\n",
       "      <td>91.547278</td>\n",
       "      <td>83.631805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>97.242120</td>\n",
       "      <td>93.588825</td>\n",
       "      <td>87.679083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>96.704871</td>\n",
       "      <td>90.186246</td>\n",
       "      <td>81.411175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>93.624642</td>\n",
       "      <td>89.219198</td>\n",
       "      <td>83.703438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>95.093123</td>\n",
       "      <td>86.461318</td>\n",
       "      <td>76.432665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Middle_90%  Middle_80%  Middle_70%\n",
       "0   96.203438   88.323782   79.154728\n",
       "1   95.988539   92.084527   87.285100\n",
       "2   89.756447   79.763610   70.702006\n",
       "3   92.048711   81.769341   72.206304\n",
       "4   96.704871   90.186246   81.411175\n",
       "5   97.063037   91.547278   83.631805\n",
       "6   97.242120   93.588825   87.679083\n",
       "7   96.704871   90.186246   81.411175\n",
       "8   93.624642   89.219198   83.703438\n",
       "9   95.093123   86.461318   76.432665"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervals_percent_df = intervals_percent_df.reset_index(drop=True)\n",
    "intervals_percent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b430aebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Middle_90%    95.042980\n",
       "Middle_80%    88.313037\n",
       "Middle_70%    80.361748\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervals_percent_df.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8a28764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_nll_score</th>\n",
       "      <th>WMAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.302207</td>\n",
       "      <td>0.230756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.304306</td>\n",
       "      <td>0.183591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.306726</td>\n",
       "      <td>0.273433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.302533</td>\n",
       "      <td>0.264649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.300207</td>\n",
       "      <td>0.217767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.303234</td>\n",
       "      <td>0.204617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12.295482</td>\n",
       "      <td>0.157612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.302200</td>\n",
       "      <td>0.217767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12.293898</td>\n",
       "      <td>0.169728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.299561</td>\n",
       "      <td>0.242239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   best_nll_score     WMAPE\n",
       "0       12.302207  0.230756\n",
       "1       12.304306  0.183591\n",
       "2       12.306726  0.273433\n",
       "3       12.302533  0.264649\n",
       "4       12.300207  0.217767\n",
       "5       12.303234  0.204617\n",
       "6       12.295482  0.157612\n",
       "7       12.302200  0.217767\n",
       "8       12.293898  0.169728\n",
       "9       12.299561  0.242239"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create df of best nll score and WMAPE\n",
    "nll_wmape = pd.DataFrame.from_dict({'best_nll_score' : best_nll_score, 'WMAPE' : wmape}, orient='index').T\n",
    "nll_wmape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "704ce6c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "best_nll_score    12.301036\n",
       "WMAPE              0.216216\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll_wmape_avg = nll_wmape.mean()\n",
    "nll_wmape_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41c35aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# House Prediction\n",
    "# Apply the best parameter set for nll and assign it to reg\n",
    "alpha_score = list()\n",
    "beta_score = list()\n",
    "y_pred_score = pd.DataFrame()\n",
    "\n",
    "for modelrun in range(10):\n",
    "    # Set up steps and pipeline\n",
    "    steps = [('imputer', SimpleImputer()),\n",
    "             ('reg', initialize_reg(n_estimators     = nll_n_estimators[modelrun],\n",
    "                                    learning_rate    = nll_learning_rate[modelrun],\n",
    "                                    minibatch_frac   = nll_minibatch_frac[modelrun],\n",
    "                                    col_sample       = nll_col_sample[modelrun],\n",
    "                                    min_samples_leaf = nll_min_samples_leaf[modelrun],\n",
    "                                    max_depth        = nll_max_depth[modelrun],\n",
    "                                    dist=data_dist,\n",
    "                                    random_state=seeds[modelrun]))]\n",
    "    pipeline = PipelineJY(steps)\n",
    "    pipeline.fit(X, y)\n",
    "    alpha_score.append(pipeline.pred_dist(X_score)[0][0])\n",
    "    beta_score.append(pipeline.pred_dist(X_score)[0][1])\n",
    "    \n",
    "y_pred_score = pd.concat([pd.Series(alpha_score), pd.Series(beta_score)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f7f6dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df of predicted, min-max probability intervals, and observed values\n",
    "def pred_dist_info_score(y_pred_params, pi_range = [0.05, 0.95]):\n",
    "    \n",
    "    alpha     = y_pred_params.iloc[:,0].values\n",
    "    beta = y_pred_params.iloc[:,1].values\n",
    "    \n",
    "    y_pred_mean = alpha / beta\n",
    "    y_pred_median = gamma.ppf(0.5, a = alpha, scale=1/beta)\n",
    "    y_pred = y_pred_median\n",
    "    \n",
    "    errors = [y_pred -  gamma.ppf(pi_range[0], a = alpha, scale=1/beta),\n",
    "              -y_pred + gamma.ppf(pi_range[1], a = alpha, scale=1/beta)]\n",
    "\n",
    "    test = pd.DataFrame({\"prediction\"  : y_pred,\n",
    "                         \"error_minus\" : errors[0],\n",
    "                         \"error_plus\"  : errors[1],\n",
    "                         \"alpha\"       : alpha,\n",
    "                         \"beta\"        : beta,\n",
    "                         \"predicted\"   : y_pred,\n",
    "                         \"lower_range\" : y_pred - errors[0],\n",
    "                         \"upper_range\" : y_pred + errors[1]}).reset_index(drop=True)\n",
    "    \n",
    "    for column in ['predicted', 'lower_range', 'upper_range']:\n",
    "        test[column] = test[column].apply(lambda x : '${0:,.0f}'.format(x))\n",
    "    \n",
    "    return test, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e4c14f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>error_minus</th>\n",
       "      <th>error_plus</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>predicted</th>\n",
       "      <th>lower_range</th>\n",
       "      <th>upper_range</th>\n",
       "      <th>best_nll_score</th>\n",
       "      <th>WMAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>162412.548961</td>\n",
       "      <td>71613.039568</td>\n",
       "      <td>102086.574049</td>\n",
       "      <td>9.887648</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>$162,413</td>\n",
       "      <td>$90,800</td>\n",
       "      <td>$264,499</td>\n",
       "      <td>12.302207</td>\n",
       "      <td>0.230756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>169501.701835</td>\n",
       "      <td>53520.155525</td>\n",
       "      <td>67917.365599</td>\n",
       "      <td>21.511442</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>$169,502</td>\n",
       "      <td>$115,982</td>\n",
       "      <td>$237,419</td>\n",
       "      <td>12.304306</td>\n",
       "      <td>0.183591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162319.677517</td>\n",
       "      <td>76555.164842</td>\n",
       "      <td>112610.365306</td>\n",
       "      <td>8.394321</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>$162,320</td>\n",
       "      <td>$85,765</td>\n",
       "      <td>$274,930</td>\n",
       "      <td>12.306726</td>\n",
       "      <td>0.273433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>162568.088621</td>\n",
       "      <td>75371.417386</td>\n",
       "      <td>109952.063726</td>\n",
       "      <td>8.753667</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>$162,568</td>\n",
       "      <td>$87,197</td>\n",
       "      <td>$272,520</td>\n",
       "      <td>12.302533</td>\n",
       "      <td>0.264649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161926.293682</td>\n",
       "      <td>70479.715446</td>\n",
       "      <td>99903.812775</td>\n",
       "      <td>10.200783</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>$161,926</td>\n",
       "      <td>$91,447</td>\n",
       "      <td>$261,830</td>\n",
       "      <td>12.300207</td>\n",
       "      <td>0.217767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>164843.053723</td>\n",
       "      <td>69876.383887</td>\n",
       "      <td>97944.442796</td>\n",
       "      <td>10.867938</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>$164,843</td>\n",
       "      <td>$94,967</td>\n",
       "      <td>$262,787</td>\n",
       "      <td>12.303234</td>\n",
       "      <td>0.204617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>166259.129555</td>\n",
       "      <td>60543.428525</td>\n",
       "      <td>80205.158396</td>\n",
       "      <td>15.527638</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>$166,259</td>\n",
       "      <td>$105,716</td>\n",
       "      <td>$246,464</td>\n",
       "      <td>12.295482</td>\n",
       "      <td>0.157612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>164094.918195</td>\n",
       "      <td>71474.802534</td>\n",
       "      <td>101345.747097</td>\n",
       "      <td>10.183240</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>$164,095</td>\n",
       "      <td>$92,620</td>\n",
       "      <td>$265,441</td>\n",
       "      <td>12.302200</td>\n",
       "      <td>0.217767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>161462.297795</td>\n",
       "      <td>41278.717846</td>\n",
       "      <td>49804.407623</td>\n",
       "      <td>34.435557</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>$161,462</td>\n",
       "      <td>$120,184</td>\n",
       "      <td>$211,267</td>\n",
       "      <td>12.293898</td>\n",
       "      <td>0.169728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>162597.156224</td>\n",
       "      <td>73842.930026</td>\n",
       "      <td>106679.696992</td>\n",
       "      <td>9.205740</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>$162,597</td>\n",
       "      <td>$88,754</td>\n",
       "      <td>$269,277</td>\n",
       "      <td>12.299561</td>\n",
       "      <td>0.242239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prediction   error_minus     error_plus      alpha      beta predicted  \\\n",
       "0  162412.548961  71613.039568  102086.574049   9.887648  0.000059  $162,413   \n",
       "1  169501.701835  53520.155525   67917.365599  21.511442  0.000125  $169,502   \n",
       "2  162319.677517  76555.164842  112610.365306   8.394321  0.000050  $162,320   \n",
       "3  162568.088621  75371.417386  109952.063726   8.753667  0.000052  $162,568   \n",
       "4  161926.293682  70479.715446   99903.812775  10.200783  0.000061  $161,926   \n",
       "5  164843.053723  69876.383887   97944.442796  10.867938  0.000064  $164,843   \n",
       "6  166259.129555  60543.428525   80205.158396  15.527638  0.000091  $166,259   \n",
       "7  164094.918195  71474.802534  101345.747097  10.183240  0.000060  $164,095   \n",
       "8  161462.297795  41278.717846   49804.407623  34.435557  0.000211  $161,462   \n",
       "9  162597.156224  73842.930026  106679.696992   9.205740  0.000055  $162,597   \n",
       "\n",
       "  lower_range upper_range  best_nll_score     WMAPE  \n",
       "0     $90,800    $264,499       12.302207  0.230756  \n",
       "1    $115,982    $237,419       12.304306  0.183591  \n",
       "2     $85,765    $274,930       12.306726  0.273433  \n",
       "3     $87,197    $272,520       12.302533  0.264649  \n",
       "4     $91,447    $261,830       12.300207  0.217767  \n",
       "5     $94,967    $262,787       12.303234  0.204617  \n",
       "6    $105,716    $246,464       12.295482  0.157612  \n",
       "7     $92,620    $265,441       12.302200  0.217767  \n",
       "8    $120,184    $211,267       12.293898  0.169728  \n",
       "9     $88,754    $269,277       12.299561  0.242239  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join nll_wmape df to score df\n",
    "score_90_df, y_errors = pred_dist_info_score(y_pred_score, pi_range = [0.05, 0.95])\n",
    "score_90_df = score_90_df.merge(nll_wmape, how='inner', left_index=True, right_index=True)\n",
    "score_90_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5fdb7683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_df(df, score_range):\n",
    "    df_avg = pd.DataFrame(df[['prediction', 'error_minus', 'error_plus',\n",
    "                              'alpha', 'beta', 'best_nll_score', 'WMAPE']].mean()).T\n",
    "    df_avg['predicted'] = df_avg['prediction']\n",
    "    df_avg['lower_range'] = df_avg['prediction'] - df_avg['error_minus']\n",
    "    df_avg['upper_range'] = df_avg['prediction'] + df_avg['error_plus']\n",
    "    for column in ['predicted', 'lower_range', 'upper_range']:\n",
    "        df_avg[column] = df_avg[column].apply(lambda x : '${0:,.0f}'.format(x))\n",
    "    df_avg['actual'] = int(ames_housing[ames_housing['PID']==scoreid]['SalePrice'].iloc[0])\n",
    "    df_avg['type'] = 'middle_{}'.format(score_range)\n",
    "    df_avg['PID'] = scoreid\n",
    "    return df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2999b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>error_minus</th>\n",
       "      <th>error_plus</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>best_nll_score</th>\n",
       "      <th>WMAPE</th>\n",
       "      <th>predicted</th>\n",
       "      <th>lower_range</th>\n",
       "      <th>upper_range</th>\n",
       "      <th>actual</th>\n",
       "      <th>type</th>\n",
       "      <th>PID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>163798.486611</td>\n",
       "      <td>66455.575559</td>\n",
       "      <td>92844.963436</td>\n",
       "      <td>13.896797</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>12.301036</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>$163,798</td>\n",
       "      <td>$97,343</td>\n",
       "      <td>$256,643</td>\n",
       "      <td>173733</td>\n",
       "      <td>middle_90</td>\n",
       "      <td>533210020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prediction   error_minus    error_plus      alpha      beta  \\\n",
       "0  163798.486611  66455.575559  92844.963436  13.896797  0.000083   \n",
       "\n",
       "   best_nll_score     WMAPE predicted lower_range upper_range  actual  \\\n",
       "0       12.301036  0.216216  $163,798     $97,343    $256,643  173733   \n",
       "\n",
       "        type        PID  \n",
       "0  middle_90  533210020  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_range = 90\n",
    "score_90_avg = get_avg_df(score_90_df, score_range)\n",
    "score_90_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1abf147b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>error_minus</th>\n",
       "      <th>error_plus</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>predicted</th>\n",
       "      <th>lower_range</th>\n",
       "      <th>upper_range</th>\n",
       "      <th>best_nll_score</th>\n",
       "      <th>WMAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>162412.548961</td>\n",
       "      <td>58196.077781</td>\n",
       "      <td>76717.527107</td>\n",
       "      <td>9.887648</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>$162,413</td>\n",
       "      <td>$104,216</td>\n",
       "      <td>$239,130</td>\n",
       "      <td>12.302207</td>\n",
       "      <td>0.230756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>169501.701835</td>\n",
       "      <td>42869.264328</td>\n",
       "      <td>51613.821552</td>\n",
       "      <td>21.511442</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>$169,502</td>\n",
       "      <td>$126,632</td>\n",
       "      <td>$221,116</td>\n",
       "      <td>12.304306</td>\n",
       "      <td>0.183591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162319.677517</td>\n",
       "      <td>62460.935004</td>\n",
       "      <td>84379.813353</td>\n",
       "      <td>8.394321</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>$162,320</td>\n",
       "      <td>$99,859</td>\n",
       "      <td>$246,699</td>\n",
       "      <td>12.306726</td>\n",
       "      <td>0.273433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>162568.088621</td>\n",
       "      <td>61430.006873</td>\n",
       "      <td>82451.168643</td>\n",
       "      <td>8.753667</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>$162,568</td>\n",
       "      <td>$101,138</td>\n",
       "      <td>$245,019</td>\n",
       "      <td>12.302533</td>\n",
       "      <td>0.264649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161926.293682</td>\n",
       "      <td>57234.107695</td>\n",
       "      <td>75117.027323</td>\n",
       "      <td>10.200783</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>$161,926</td>\n",
       "      <td>$104,692</td>\n",
       "      <td>$237,043</td>\n",
       "      <td>12.300207</td>\n",
       "      <td>0.217767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>164843.053723</td>\n",
       "      <td>56664.005338</td>\n",
       "      <td>73721.492365</td>\n",
       "      <td>10.867938</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>$164,843</td>\n",
       "      <td>$108,179</td>\n",
       "      <td>$238,565</td>\n",
       "      <td>12.303234</td>\n",
       "      <td>0.204617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>166259.129555</td>\n",
       "      <td>48751.262815</td>\n",
       "      <td>60695.987912</td>\n",
       "      <td>15.527638</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>$166,259</td>\n",
       "      <td>$117,508</td>\n",
       "      <td>$226,955</td>\n",
       "      <td>12.295482</td>\n",
       "      <td>0.157612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>164094.918195</td>\n",
       "      <td>58044.456263</td>\n",
       "      <td>76198.992060</td>\n",
       "      <td>10.183240</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>$164,095</td>\n",
       "      <td>$106,050</td>\n",
       "      <td>$240,294</td>\n",
       "      <td>12.302200</td>\n",
       "      <td>0.217767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>161462.297795</td>\n",
       "      <td>32863.313216</td>\n",
       "      <td>38040.543351</td>\n",
       "      <td>34.435557</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>$161,462</td>\n",
       "      <td>$128,599</td>\n",
       "      <td>$199,503</td>\n",
       "      <td>12.293898</td>\n",
       "      <td>0.169728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>162597.156224</td>\n",
       "      <td>60109.821680</td>\n",
       "      <td>80069.490716</td>\n",
       "      <td>9.205740</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>$162,597</td>\n",
       "      <td>$102,487</td>\n",
       "      <td>$242,667</td>\n",
       "      <td>12.299561</td>\n",
       "      <td>0.242239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prediction   error_minus    error_plus      alpha      beta predicted  \\\n",
       "0  162412.548961  58196.077781  76717.527107   9.887648  0.000059  $162,413   \n",
       "1  169501.701835  42869.264328  51613.821552  21.511442  0.000125  $169,502   \n",
       "2  162319.677517  62460.935004  84379.813353   8.394321  0.000050  $162,320   \n",
       "3  162568.088621  61430.006873  82451.168643   8.753667  0.000052  $162,568   \n",
       "4  161926.293682  57234.107695  75117.027323  10.200783  0.000061  $161,926   \n",
       "5  164843.053723  56664.005338  73721.492365  10.867938  0.000064  $164,843   \n",
       "6  166259.129555  48751.262815  60695.987912  15.527638  0.000091  $166,259   \n",
       "7  164094.918195  58044.456263  76198.992060  10.183240  0.000060  $164,095   \n",
       "8  161462.297795  32863.313216  38040.543351  34.435557  0.000211  $161,462   \n",
       "9  162597.156224  60109.821680  80069.490716   9.205740  0.000055  $162,597   \n",
       "\n",
       "  lower_range upper_range  best_nll_score     WMAPE  \n",
       "0    $104,216    $239,130       12.302207  0.230756  \n",
       "1    $126,632    $221,116       12.304306  0.183591  \n",
       "2     $99,859    $246,699       12.306726  0.273433  \n",
       "3    $101,138    $245,019       12.302533  0.264649  \n",
       "4    $104,692    $237,043       12.300207  0.217767  \n",
       "5    $108,179    $238,565       12.303234  0.204617  \n",
       "6    $117,508    $226,955       12.295482  0.157612  \n",
       "7    $106,050    $240,294       12.302200  0.217767  \n",
       "8    $128,599    $199,503       12.293898  0.169728  \n",
       "9    $102,487    $242,667       12.299561  0.242239  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join nll_wmape df to score df\n",
    "score_80_df, y_errors = pred_dist_info_score(y_pred_score, pi_range = [0.1, 0.9])\n",
    "score_80_df = score_80_df.merge(nll_wmape, how='inner', left_index=True, right_index=True)\n",
    "score_80_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "450fbcce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>error_minus</th>\n",
       "      <th>error_plus</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>best_nll_score</th>\n",
       "      <th>WMAPE</th>\n",
       "      <th>predicted</th>\n",
       "      <th>lower_range</th>\n",
       "      <th>upper_range</th>\n",
       "      <th>actual</th>\n",
       "      <th>type</th>\n",
       "      <th>PID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>163798.486611</td>\n",
       "      <td>53862.325099</td>\n",
       "      <td>69900.586438</td>\n",
       "      <td>13.896797</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>12.301036</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>$163,798</td>\n",
       "      <td>$109,936</td>\n",
       "      <td>$233,699</td>\n",
       "      <td>173733</td>\n",
       "      <td>middle_80</td>\n",
       "      <td>533210020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prediction   error_minus    error_plus      alpha      beta  \\\n",
       "0  163798.486611  53862.325099  69900.586438  13.896797  0.000083   \n",
       "\n",
       "   best_nll_score     WMAPE predicted lower_range upper_range  actual  \\\n",
       "0       12.301036  0.216216  $163,798    $109,936    $233,699  173733   \n",
       "\n",
       "        type        PID  \n",
       "0  middle_80  533210020  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_range = 80\n",
    "score_80_avg = get_avg_df(score_80_df, score_range)\n",
    "score_80_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20f6112a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>error_minus</th>\n",
       "      <th>error_plus</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>predicted</th>\n",
       "      <th>lower_range</th>\n",
       "      <th>upper_range</th>\n",
       "      <th>best_nll_score</th>\n",
       "      <th>WMAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>162412.548961</td>\n",
       "      <td>48402.806020</td>\n",
       "      <td>60524.737763</td>\n",
       "      <td>9.887648</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>$162,413</td>\n",
       "      <td>$114,010</td>\n",
       "      <td>$222,937</td>\n",
       "      <td>12.302207</td>\n",
       "      <td>0.230756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>169501.701835</td>\n",
       "      <td>35316.697929</td>\n",
       "      <td>41037.774933</td>\n",
       "      <td>21.511442</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>$169,502</td>\n",
       "      <td>$134,185</td>\n",
       "      <td>$210,539</td>\n",
       "      <td>12.304306</td>\n",
       "      <td>0.183591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162319.677517</td>\n",
       "      <td>52086.616559</td>\n",
       "      <td>66433.844034</td>\n",
       "      <td>8.394321</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>$162,320</td>\n",
       "      <td>$110,233</td>\n",
       "      <td>$228,754</td>\n",
       "      <td>12.306726</td>\n",
       "      <td>0.273433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>162568.088621</td>\n",
       "      <td>51191.201974</td>\n",
       "      <td>64950.363454</td>\n",
       "      <td>8.753667</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>$162,568</td>\n",
       "      <td>$111,377</td>\n",
       "      <td>$227,518</td>\n",
       "      <td>12.302533</td>\n",
       "      <td>0.264649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161926.293682</td>\n",
       "      <td>47580.273142</td>\n",
       "      <td>59284.055537</td>\n",
       "      <td>10.200783</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>$161,926</td>\n",
       "      <td>$114,346</td>\n",
       "      <td>$221,210</td>\n",
       "      <td>12.300207</td>\n",
       "      <td>0.217767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>164843.053723</td>\n",
       "      <td>47062.462862</td>\n",
       "      <td>58225.576955</td>\n",
       "      <td>10.867938</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>$164,843</td>\n",
       "      <td>$117,781</td>\n",
       "      <td>$223,069</td>\n",
       "      <td>12.303234</td>\n",
       "      <td>0.204617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>166259.129555</td>\n",
       "      <td>40302.784050</td>\n",
       "      <td>48118.467935</td>\n",
       "      <td>15.527638</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>$166,259</td>\n",
       "      <td>$125,956</td>\n",
       "      <td>$214,378</td>\n",
       "      <td>12.295482</td>\n",
       "      <td>0.157612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>164094.918195</td>\n",
       "      <td>48255.183316</td>\n",
       "      <td>60136.743015</td>\n",
       "      <td>10.183240</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>$164,095</td>\n",
       "      <td>$115,840</td>\n",
       "      <td>$224,232</td>\n",
       "      <td>12.302200</td>\n",
       "      <td>0.217767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>161462.297795</td>\n",
       "      <td>26964.460168</td>\n",
       "      <td>30351.251575</td>\n",
       "      <td>34.435557</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>$161,462</td>\n",
       "      <td>$134,498</td>\n",
       "      <td>$191,814</td>\n",
       "      <td>12.293898</td>\n",
       "      <td>0.169728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>162597.156224</td>\n",
       "      <td>50050.261922</td>\n",
       "      <td>63114.139914</td>\n",
       "      <td>9.205740</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>$162,597</td>\n",
       "      <td>$112,547</td>\n",
       "      <td>$225,711</td>\n",
       "      <td>12.299561</td>\n",
       "      <td>0.242239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prediction   error_minus    error_plus      alpha      beta predicted  \\\n",
       "0  162412.548961  48402.806020  60524.737763   9.887648  0.000059  $162,413   \n",
       "1  169501.701835  35316.697929  41037.774933  21.511442  0.000125  $169,502   \n",
       "2  162319.677517  52086.616559  66433.844034   8.394321  0.000050  $162,320   \n",
       "3  162568.088621  51191.201974  64950.363454   8.753667  0.000052  $162,568   \n",
       "4  161926.293682  47580.273142  59284.055537  10.200783  0.000061  $161,926   \n",
       "5  164843.053723  47062.462862  58225.576955  10.867938  0.000064  $164,843   \n",
       "6  166259.129555  40302.784050  48118.467935  15.527638  0.000091  $166,259   \n",
       "7  164094.918195  48255.183316  60136.743015  10.183240  0.000060  $164,095   \n",
       "8  161462.297795  26964.460168  30351.251575  34.435557  0.000211  $161,462   \n",
       "9  162597.156224  50050.261922  63114.139914   9.205740  0.000055  $162,597   \n",
       "\n",
       "  lower_range upper_range  best_nll_score     WMAPE  \n",
       "0    $114,010    $222,937       12.302207  0.230756  \n",
       "1    $134,185    $210,539       12.304306  0.183591  \n",
       "2    $110,233    $228,754       12.306726  0.273433  \n",
       "3    $111,377    $227,518       12.302533  0.264649  \n",
       "4    $114,346    $221,210       12.300207  0.217767  \n",
       "5    $117,781    $223,069       12.303234  0.204617  \n",
       "6    $125,956    $214,378       12.295482  0.157612  \n",
       "7    $115,840    $224,232       12.302200  0.217767  \n",
       "8    $134,498    $191,814       12.293898  0.169728  \n",
       "9    $112,547    $225,711       12.299561  0.242239  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join nll_wmape df to score df\n",
    "score_70_df, y_errors = pred_dist_info_score(y_pred_score, pi_range = [0.15, 0.85])\n",
    "score_70_df = score_70_df.merge(nll_wmape, how='inner', left_index=True, right_index=True)\n",
    "score_70_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f3bd66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>error_minus</th>\n",
       "      <th>error_plus</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>best_nll_score</th>\n",
       "      <th>WMAPE</th>\n",
       "      <th>predicted</th>\n",
       "      <th>lower_range</th>\n",
       "      <th>upper_range</th>\n",
       "      <th>actual</th>\n",
       "      <th>type</th>\n",
       "      <th>PID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>163798.486611</td>\n",
       "      <td>44721.274794</td>\n",
       "      <td>55217.695512</td>\n",
       "      <td>13.896797</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>12.301036</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>$163,798</td>\n",
       "      <td>$119,077</td>\n",
       "      <td>$219,016</td>\n",
       "      <td>173733</td>\n",
       "      <td>middle_70</td>\n",
       "      <td>533210020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prediction   error_minus    error_plus      alpha      beta  \\\n",
       "0  163798.486611  44721.274794  55217.695512  13.896797  0.000083   \n",
       "\n",
       "   best_nll_score     WMAPE predicted lower_range upper_range  actual  \\\n",
       "0       12.301036  0.216216  $163,798    $119,077    $219,016  173733   \n",
       "\n",
       "        type        PID  \n",
       "0  middle_70  533210020  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_range = 70\n",
    "score_70_avg = get_avg_df(score_70_df, score_range)\n",
    "score_70_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0bdca2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = pd.concat([score_90_avg, score_80_avg, score_70_avg]).reset_index(drop=True)\n",
    "#score.to_csv('processed_data/10X_ngboost_gamma_score_inst.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53b9f603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>error_minus</th>\n",
       "      <th>error_plus</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>best_nll_score</th>\n",
       "      <th>WMAPE</th>\n",
       "      <th>predicted</th>\n",
       "      <th>lower_range</th>\n",
       "      <th>upper_range</th>\n",
       "      <th>actual</th>\n",
       "      <th>type</th>\n",
       "      <th>PID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>163798.486611</td>\n",
       "      <td>66455.575559</td>\n",
       "      <td>92844.963436</td>\n",
       "      <td>13.896797</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>12.301036</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>$163,798</td>\n",
       "      <td>$97,343</td>\n",
       "      <td>$256,643</td>\n",
       "      <td>173733</td>\n",
       "      <td>middle_90</td>\n",
       "      <td>533210020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>163798.486611</td>\n",
       "      <td>53862.325099</td>\n",
       "      <td>69900.586438</td>\n",
       "      <td>13.896797</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>12.301036</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>$163,798</td>\n",
       "      <td>$109,936</td>\n",
       "      <td>$233,699</td>\n",
       "      <td>173733</td>\n",
       "      <td>middle_80</td>\n",
       "      <td>533210020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>163798.486611</td>\n",
       "      <td>44721.274794</td>\n",
       "      <td>55217.695512</td>\n",
       "      <td>13.896797</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>12.301036</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>$163,798</td>\n",
       "      <td>$119,077</td>\n",
       "      <td>$219,016</td>\n",
       "      <td>173733</td>\n",
       "      <td>middle_70</td>\n",
       "      <td>533210020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prediction   error_minus    error_plus      alpha      beta  \\\n",
       "0  163798.486611  66455.575559  92844.963436  13.896797  0.000083   \n",
       "1  163798.486611  53862.325099  69900.586438  13.896797  0.000083   \n",
       "2  163798.486611  44721.274794  55217.695512  13.896797  0.000083   \n",
       "\n",
       "   best_nll_score     WMAPE predicted lower_range upper_range  actual  \\\n",
       "0       12.301036  0.216216  $163,798     $97,343    $256,643  173733   \n",
       "1       12.301036  0.216216  $163,798    $109,936    $233,699  173733   \n",
       "2       12.301036  0.216216  $163,798    $119,077    $219,016  173733   \n",
       "\n",
       "        type        PID  \n",
       "0  middle_90  533210020  \n",
       "1  middle_80  533210020  \n",
       "2  middle_70  533210020  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c68e0d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.10.13",
   "language": "python",
   "name": "python3.10.13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
